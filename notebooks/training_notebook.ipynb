{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "['/usr/lib/python311.zip', '/usr/lib/python3.11', '/usr/lib/python3.11/lib-dynload', '', '/usr/local/lib/python3.11/dist-packages', '/workspace/scratch_repository/src', '/usr/lib/python3/dist-packages', '/workspace/scratch_repository', '/tmp/tmp6pyufkme', '/workspace/scratch_repository']\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "DATASET = os.getenv(\"DATASET\", \"../../enveda_library_subset.parquet\")\n",
    "BASE_MODEL = \"seyonec/ChemBERTa-zinc-base-v1\"\n",
    "MAX_FRAGMENTS = 512 # from anton, max number of mzs/intensities\n",
    "MAX_SEQ_LENGTH = 512 # base model max seq length\n",
    "SUPPLEMENTARY_DATA_DIM = 75\n",
    "ENABLE_PROFILING = False # If turned on, will profile the training\n",
    "BATCH_SIZE = int(os.getenv(\"BATCH_SIZE\", 64)) # Note: if using CUDA, it'll automatically find the optimal batch size\n",
    "NUM_EPOCHS = int(os.getenv(\"NUM_EPOCHS\", 16))\n",
    "## Set WANDB_API_KEY environment variable to enable logging to wandb\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "os.environ[\"WANDB_API_KEY\"] = \"69f075ac6ff5b82fb8e32313942465d0a23c6ead\"\n",
    "\n",
    "import sys\n",
    "sys.path.append('/workspace/scratch_repository')\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tYhe3fk-sblS"
   },
   "source": [
    "# Messing around with ChemBERTa for fun and for education\n",
    "\n",
    "The first half of this colab is just fun experiments trying to understand ChemBERTa and it's tokenizer better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420,
     "referenced_widgets": [
      "09447f7d805a456a8d9df123079fef9b",
      "491c2c5348da4cebb59112f76ff21867",
      "fe9ba8c3b518443ba11fd1e700dd2c24",
      "017803aafcb84942bd04ae4b6014d713",
      "7bb64ec2bc31458fac09dafbafc66030",
      "48ba3adb18ee45b085dcfcc74b8e4d19",
      "90c266cbe71d46aaade3ab541889fe07",
      "ed10bed1b375495cb383786278b88953",
      "0186504a6df04889965a532aeaa3058c",
      "9365963655bf4a6f9f65418af1213afb",
      "e8e0cfd2025e41cfb5ea102586988b28",
      "6b54217022de4316a071ee63832b77fe",
      "3cf79467e3384aeba7e957596b912e29",
      "d23dd09659b9428f8cc8083f44e04709",
      "a75c8346a8f74f43941aa43700e6b2d8",
      "e5968c80140b4a71978dbb453ee75af2",
      "285f3c7db7d448a7a9ed62b2f9324e53",
      "e02702dc96744f0bb3304606cfa29e24",
      "5810f7fa342f4543834d8274abe552f5",
      "433bfc6fb35a4199b1cedfbaf5f5a15e",
      "8d37ac015a0f4caebf5455c7c16284dc",
      "f3084e63613741098216632a5f92ef98",
      "1b99d732290a4190982895ff640ea719",
      "b284f3ac0854497fbab925eeb1ded0df",
      "01638020753146678ee0a7692603b6c2",
      "6cd3e39a24fa4ed490ea0567c51c6eee",
      "e0c994de1d654e92ac91d661932ebdfa",
      "2fa221bf24cb4bdf9695b5f593b0d818",
      "502de19d537d41a7b151ca5798f46a72",
      "b689e92305ae4b6693991b37e894f4a0",
      "50e84fe3afd94297a3f198d0dfc4654b",
      "dcc379d6713f47529ea18e30482cfa29",
      "6d6719e9bdcc411c95f60201ee37119a",
      "ec2a4d26292d4606bdcee5c2a0ea5f70",
      "cf7c0c5e780145cf90de13cd375c1cce",
      "6cc566ec625c4251908f083a4ac5e972",
      "ea2e9aa05204487fa884178986a59380",
      "6ff00156a8d1407e8a03899aede36f60",
      "57196d402589425baba759c1f92b3fee",
      "931340e0216b4cdd940a7041f14b62f1",
      "ccba3a5e8f3f4f08b79e5cad740b78b8",
      "f762dd67830c45a1b8725313b92346e4",
      "bc455b59103e4404b9f9b124d6999b3c",
      "d178a1d70c32435482c10d6824bf4131",
      "7de2b548546d4c58b4e1af83cdf618e7",
      "b5c94d24b105493796b8f70d4adb55a7",
      "be8b9e625b624ad89abb785ffdb352b9",
      "7f60ccd803d8490f990a58518b1aa4dd",
      "038ff99e2ffc4f7db7ecd54333a3d71e",
      "177f0b132f2f40b9b63a048635f0dc70",
      "47da5e41d88d4bc6bfb496adacddba30",
      "604c8bed2d6f4c04bb9ae2b78c6f4aea",
      "c83d02b54fe94d6889aae124641f43eb",
      "4df1d8407ea74a3193426b27a15eeaa9",
      "67e3bc2be1034a73be1fc0b3b97da027",
      "f53b7a64750849d18bb4df54237a1110",
      "f7b208a676664b59a90d7d38293df4dd",
      "504f51d204af44b7915060072ea359b2",
      "1f2793e435b04dc7b9502f643a98d533",
      "c9e22b771e9e49ad8354902723d9b951",
      "201c3ab1ff3a46128961e12e4edb2a01",
      "bd46618a5bce46ec840bae0adb001564",
      "ac00b65c79fc4b73a3e2d9d437001e3f",
      "d9c52550dcb8430a891ada649a35d5de",
      "4a99e037f63b4dbfa9d2f58912c46167",
      "f89668c6b88c4bad853403c95eed4fff"
     ]
    },
    "id": "KPjZH305wYrn",
    "outputId": "a36beb4d-b472-44c7-aed8-c200e1cc515c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--seyonec--ChemBERTa-zinc-base-v1/snapshots/761d6a18cf99db371e0b43baf3e2d21b3e865a20/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"seyonec/ChemBERTa-zinc-base-v1\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.45.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 767\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--seyonec--ChemBERTa-zinc-base-v1/snapshots/761d6a18cf99db371e0b43baf3e2d21b3e865a20/pytorch_model.bin\n",
      "Some weights of the model checkpoint at seyonec/ChemBERTa-zinc-base-v1 were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of RobertaForMaskedLM were initialized from the model checkpoint at seyonec/ChemBERTa-zinc-base-v1.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForMaskedLM for predictions without further training.\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--seyonec--ChemBERTa-zinc-base-v1/snapshots/761d6a18cf99db371e0b43baf3e2d21b3e865a20/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"seyonec/ChemBERTa-zinc-base-v1\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.45.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 767\n",
      "}\n",
      "\n",
      "loading file vocab.json from cache at /root/.cache/huggingface/hub/models--seyonec--ChemBERTa-zinc-base-v1/snapshots/761d6a18cf99db371e0b43baf3e2d21b3e865a20/vocab.json\n",
      "loading file merges.txt from cache at /root/.cache/huggingface/hub/models--seyonec--ChemBERTa-zinc-base-v1/snapshots/761d6a18cf99db371e0b43baf3e2d21b3e865a20/merges.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--seyonec--ChemBERTa-zinc-base-v1/snapshots/761d6a18cf99db371e0b43baf3e2d21b3e865a20/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--seyonec--ChemBERTa-zinc-base-v1/snapshots/761d6a18cf99db371e0b43baf3e2d21b3e865a20/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--seyonec--ChemBERTa-zinc-base-v1/snapshots/761d6a18cf99db371e0b43baf3e2d21b3e865a20/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"seyonec/ChemBERTa-zinc-base-v1\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.45.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 767\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--seyonec--ChemBERTa-zinc-base-v1/snapshots/761d6a18cf99db371e0b43baf3e2d21b3e865a20/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"seyonec/ChemBERTa-zinc-base-v1\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.45.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 767\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import (AutoModelForMaskedLM, AutoTokenizer)\n",
    "\n",
    "model = AutoModelForMaskedLM.from_pretrained(BASE_MODEL)\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y_cMXHTFeMOy"
   },
   "source": [
    "# Data prep\n",
    "\n",
    "\n",
    "These are the columns in the data set:\n",
    "\n",
    "precursor_mz - f64\n",
    "precursor_charge - f64\n",
    "mzs - list[f64]\n",
    "intensities - list[f64]\n",
    "in_silico - bool\n",
    "smiles - str\n",
    "adduct - str\n",
    "collision_energy - str\n",
    "instrument_type - str\n",
    "compound_class - str\n",
    "entropy - f64\n",
    "scaffold_smiles - str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "nyTWxIYveLsl",
    "outputId": "b83c7ecc-b236-47ff-9062-4dcb1e3db1f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['precursor_mz', 'precursor_charge', 'mzs', 'intensities', 'in_silico', 'smiles', 'adduct', 'collision_energy', 'instrument_type', 'compound_class', 'entropy', 'scaffold_smiles']\n",
      "['precursor_mz', 'precursor_charge', 'mzs', 'intensities', 'in_silico', 'smiles', 'adduct', 'collision_energy', 'instrument_type', 'compound_class', 'entropy', 'scaffold_smiles']\n",
      "shape: (5, 12)\n",
      "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬──────────┬───────────┐\n",
      "│ precursor ┆ precursor ┆ mzs       ┆ intensiti ┆ … ┆ instrumen ┆ compound_ ┆ entropy  ┆ scaffold_ │\n",
      "│ _mz       ┆ _charge   ┆ ---       ┆ es        ┆   ┆ t_type    ┆ class     ┆ ---      ┆ smiles    │\n",
      "│ ---       ┆ ---       ┆ list[f64] ┆ ---       ┆   ┆ ---       ┆ ---       ┆ f64      ┆ ---       │\n",
      "│ f64       ┆ f64       ┆           ┆ list[f64] ┆   ┆ str       ┆ str       ┆          ┆ str       │\n",
      "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪══════════╪═══════════╡\n",
      "│ 441.43022 ┆ 1.0       ┆ [29.03858 ┆ [0.026925 ┆ … ┆ cfm-predi ┆ Fatty     ┆ 4.337069 ┆           │\n",
      "│ 2         ┆           ┆ ,         ┆ ,         ┆   ┆ ct 4      ┆ alcohols  ┆          ┆           │\n",
      "│           ┆           ┆ 39.02293, ┆ 0.010124, ┆   ┆           ┆           ┆          ┆           │\n",
      "│           ┆           ┆ …         ┆ …         ┆   ┆           ┆           ┆          ┆           │\n",
      "│           ┆           ┆ 441.430…  ┆ 0.56712…  ┆   ┆           ┆           ┆          ┆           │\n",
      "│ 439.41567 ┆ -1.0      ┆ [41.00329 ┆ [0.371051 ┆ … ┆ cfm-predi ┆ Fatty     ┆ 4.103735 ┆           │\n",
      "│           ┆           ┆ ,         ┆ , 0.021,  ┆   ┆ ct 4      ┆ alcohols  ┆          ┆           │\n",
      "│           ┆           ┆ 41.03967, ┆ … 1.0]    ┆   ┆           ┆           ┆          ┆           │\n",
      "│           ┆           ┆ …         ┆           ┆   ┆           ┆           ┆          ┆           │\n",
      "│           ┆           ┆ 439.415…  ┆           ┆   ┆           ┆           ┆          ┆           │\n",
      "│ 501.394   ┆ 1.0       ┆ [145.1003 ┆ [0.184781 ┆ … ┆ qTof      ┆ Fatty     ┆ 4.119506 ┆           │\n",
      "│           ┆           ┆ 11, 146.1 ┆ ,         ┆   ┆           ┆ acid      ┆          ┆           │\n",
      "│           ┆           ┆ 02829, …  ┆ 0.02939,  ┆   ┆           ┆ estolides ┆          ┆           │\n",
      "│           ┆           ┆ 504…      ┆ …         ┆   ┆           ┆           ┆          ┆           │\n",
      "│           ┆           ┆           ┆ 0.013968… ┆   ┆           ┆           ┆          ┆           │\n",
      "│ 460.306   ┆ 1.0       ┆ [77.03889 ┆ [0.015568 ┆ … ┆ qTof      ┆ N-acyl    ┆ 3.788878 ┆           │\n",
      "│           ┆           ┆ 5, 79.053 ┆ ,         ┆   ┆           ┆ amines    ┆          ┆           │\n",
      "│           ┆           ┆ 856, …    ┆ 0.061545, ┆   ┆           ┆           ┆          ┆           │\n",
      "│           ┆           ┆ 463.2…    ┆ …         ┆   ┆           ┆           ┆          ┆           │\n",
      "│           ┆           ┆           ┆ 0.02167…  ┆   ┆           ┆           ┆          ┆           │\n",
      "│ 103.07535 ┆ 1.0       ┆ [27.02293 ┆ [0.019176 ┆ … ┆ cfm-predi ┆ Wax monoe ┆ 1.92798  ┆           │\n",
      "│ 6         ┆           ┆ ,         ┆ ,         ┆   ┆ ct 4      ┆ sters     ┆          ┆           │\n",
      "│           ┆           ┆ 29.00219, ┆ 0.004482, ┆   ┆           ┆           ┆          ┆           │\n",
      "│           ┆           ┆ …         ┆ …         ┆   ┆           ┆           ┆          ┆           │\n",
      "│           ┆           ┆ 103.075…  ┆ 0.00249…  ┆   ┆           ┆           ┆          ┆           │\n",
      "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴──────────┴───────────┘\n",
      "shape: (5, 12)\n",
      "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬──────────┬───────────┐\n",
      "│ precursor ┆ precursor ┆ mzs       ┆ intensiti ┆ … ┆ instrumen ┆ compound_ ┆ entropy  ┆ scaffold_ │\n",
      "│ _mz       ┆ _charge   ┆ ---       ┆ es        ┆   ┆ t_type    ┆ class     ┆ ---      ┆ smiles    │\n",
      "│ ---       ┆ ---       ┆ list[f64] ┆ ---       ┆   ┆ ---       ┆ ---       ┆ f64      ┆ ---       │\n",
      "│ f64       ┆ f64       ┆           ┆ list[f64] ┆   ┆ str       ┆ str       ┆          ┆ str       │\n",
      "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪══════════╪═══════════╡\n",
      "│ 491.23291 ┆ 1.0       ┆ [40.01818 ┆ [0.003079 ┆ … ┆ cfm-predi ┆ Carbazole ┆ 4.219902 ┆ O=C1C(=O) │\n",
      "│ 9         ┆           ┆ ,         ┆ ,         ┆   ┆ ct 4      ┆ alkaloids ┆          ┆ C(c2c[nH] │\n",
      "│           ┆           ┆ 41.03858, ┆ 0.073577, ┆   ┆           ┆           ┆          ┆ c3ccccc23 │\n",
      "│           ┆           ┆ …         ┆ … 1.0]    ┆   ┆           ┆           ┆          ┆ )=C…      │\n",
      "│           ┆           ┆ 491.232…  ┆           ┆   ┆           ┆           ┆          ┆           │\n",
      "│ 421.15576 ┆ -1.0      ┆ [55.05532 ┆ [0.027687 ┆ … ┆ cfm-predi ┆ Simple    ┆ 3.684411 ┆ O=C1C(=O) │\n",
      "│ 7         ┆           ┆ ,         ┆ ,         ┆   ┆ ct 4      ┆ indole    ┆          ┆ C(c2c[nH] │\n",
      "│           ┆           ┆ 57.07097, ┆ 0.015336, ┆   ┆           ┆ alkaloids ┆          ┆ c3ccccc23 │\n",
      "│           ┆           ┆ …         ┆ … 1.0]    ┆   ┆           ┆           ┆          ┆ )=C…      │\n",
      "│           ┆           ┆ 421.155…  ┆           ┆   ┆           ┆           ┆          ┆           │\n",
      "│ 489.21836 ┆ -1.0      ┆ [55.05532 ┆ [0.005299 ┆ … ┆ cfm-predi ┆ Carbazole ┆ 3.594223 ┆ O=C1C(=O) │\n",
      "│ 7         ┆           ┆ ,         ┆ ,         ┆   ┆ ct 4      ┆ alkaloids ┆          ┆ C(c2c[nH] │\n",
      "│           ┆           ┆ 57.07097, ┆ 0.004494, ┆   ┆           ┆           ┆          ┆ c3ccccc23 │\n",
      "│           ┆           ┆ …         ┆ … 1.0]    ┆   ┆           ┆           ┆          ┆ )=C…      │\n",
      "│           ┆           ┆ 489.218…  ┆           ┆   ┆           ┆           ┆          ┆           │\n",
      "│ 521.20819 ┆ -1.0      ┆ [118.0662 ┆ [0.019208 ┆ … ┆ cfm-predi ┆ Carbazole ┆ 3.965342 ┆ O=C1C(=O) │\n",
      "│ 6         ┆           ┆ 2, 128.05 ┆ ,         ┆   ┆ ct 4      ┆ alkaloids ┆          ┆ C(c2c[nH] │\n",
      "│           ┆           ┆ 057, …    ┆ 0.034728, ┆   ┆           ┆           ┆          ┆ c3ccccc23 │\n",
      "│           ┆           ┆ 521.2…    ┆ … 1.0]    ┆   ┆           ┆           ┆          ┆ )C(…      │\n",
      "│ 523.22274 ┆ 1.0       ┆ [43.05423 ┆ [0.035174 ┆ … ┆ cfm-predi ┆ Carbazole ┆ 3.967363 ┆ O=C1C(=O) │\n",
      "│ 8         ┆           ┆ ,         ┆ ,         ┆   ┆ ct 4      ┆ alkaloids ┆          ┆ C(c2c[nH] │\n",
      "│           ┆           ┆ 55.05423, ┆ 0.07687,  ┆   ┆           ┆           ┆          ┆ c3ccccc23 │\n",
      "│           ┆           ┆ …         ┆ … 1.0]    ┆   ┆           ┆           ┆          ┆ )C(…      │\n",
      "│           ┆           ┆ 523.222…  ┆           ┆   ┆           ┆           ┆          ┆           │\n",
      "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴──────────┴───────────┘\n",
      "Prepared data already exists for train split, skipping\n",
      "Reading prepared data from disk (prepared_train.parquet)\n",
      "Prepared data already exists for test split, skipping\n",
      "Reading prepared data from disk (prepared_test.parquet)\n"
     ]
    }
   ],
   "source": [
    "# import the data (with pandas?)\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "## Load the dataset (for some reason this didn't work for me)\n",
    "# df = pd.read_parquet('enveda_library_subset 2.parquet')\n",
    "\n",
    "# print(df.head())\n",
    "\n",
    "\n",
    "# custom Dataset class for all the types of data.\n",
    "# I think we might want to make a new 'column' of data that combines mzs and intensities into \"label\"\n",
    "\n",
    "from src.team5.data.data_loader import SMILESDataset\n",
    "from src.team5.data.data_split import sort_dataframe_by_scaffold, split_dataframe\n",
    "from src.team5.data.prepare import tensorize\n",
    "\n",
    "df = pl.read_parquet(DATASET)\n",
    "\n",
    "df_sorted = sort_dataframe_by_scaffold(df)\n",
    "\n",
    "df_train, df_test = split_dataframe(df_sorted, split_ratio=0.9)\n",
    "\n",
    "# Print column names\n",
    "print(df_train.columns)\n",
    "print(df_test.columns)\n",
    "print(df_train.head())\n",
    "print(df_test.head())\n",
    "\n",
    "(train_tokenized_smiles, train_attention_mask, train_labels, train_supplementary_data) = tensorize(df_train, split=\"train\")\n",
    "(test_tokenized_smiles, test_attention_mask, test_labels, test_supplementary_data) = tensorize(df_test, split=\"test\")\n",
    "\n",
    "train_dataset = SMILESDataset(train_tokenized_smiles, train_attention_mask, train_labels, train_supplementary_data)\n",
    "test_dataset = SMILESDataset(test_tokenized_smiles, test_attention_mask, test_labels, test_supplementary_data)\n",
    "\n",
    "## batch?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': torch.int64, 'attention_mask': torch.int64, 'labels': torch.float32, 'supplementary_data': torch.float32}\n"
     ]
    }
   ],
   "source": [
    "print({k:v.dtype for k,v in train_dataset[0].items()})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fENovYIHeaOO"
   },
   "source": [
    "# Custom model for our problem\n",
    "This is probably the most important part in terms of design choices. We are changing the ChemBERTa model by adding on something at the end. This new module will take the hidden SMILES embedding from the last hidden layer as input. It will also take in all the other data about the precusor molecule and experimental conditions (eg, precusor mz, collison energy etc). For now, let's call that supplementary data.\n",
    "\n",
    "I've written the simplest possible thing here: a single linear layer that takes the embedding of the entire seq, concatinated with all the supplementary data for the example. It outputs \"labels\", which is mzs and intensities zipped together.\n",
    "\n",
    "The reason for making a single module output both mzs and intensities is because there needs to be the same number of fragments per example, and the two numbers are very related.\n",
    "\n",
    "A single linear layer is probably a terrible choice though, since this is the only layer that sees all the supplementary data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "rMogXqZteZ1Z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomChemBERTaModel(\n",
      "  (model): RobertaForMaskedLM(\n",
      "    (roberta): RobertaModel(\n",
      "      (embeddings): RobertaEmbeddings(\n",
      "        (word_embeddings): Embedding(767, 768, padding_idx=1)\n",
      "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "        (token_type_embeddings): Embedding(1, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): RobertaEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0-5): 6 x RobertaLayer(\n",
      "            (attention): RobertaAttention(\n",
      "              (self): RobertaSdpaSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): RobertaSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): RobertaIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): RobertaOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (lm_head): RobertaLMHead(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (decoder): Linear(in_features=768, out_features=767, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (final_layers): FinalLayers(\n",
      "    (layer1): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (activation1): ReLU()\n",
      "    (dropout1): Dropout(p=0.1, inplace=False)\n",
      "    (layernorm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (layer2): Linear(in_features=843, out_features=3, bias=True)\n",
      "    (activation2): ReLU()\n",
      "    (dropout2): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "model.roberta.embeddings.word_embeddings.weight has shape torch.Size([767, 768])\n",
      "model.roberta.embeddings.position_embeddings.weight has shape torch.Size([514, 768])\n",
      "model.roberta.embeddings.token_type_embeddings.weight has shape torch.Size([1, 768])\n",
      "model.roberta.embeddings.LayerNorm.weight has shape torch.Size([768])\n",
      "model.roberta.embeddings.LayerNorm.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.0.attention.self.query.weight has shape torch.Size([768, 768])\n",
      "model.roberta.encoder.layer.0.attention.self.query.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.0.attention.self.key.weight has shape torch.Size([768, 768])\n",
      "model.roberta.encoder.layer.0.attention.self.key.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.0.attention.self.value.weight has shape torch.Size([768, 768])\n",
      "model.roberta.encoder.layer.0.attention.self.value.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.0.attention.output.dense.weight has shape torch.Size([768, 768])\n",
      "model.roberta.encoder.layer.0.attention.output.dense.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.0.attention.output.LayerNorm.weight has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.0.attention.output.LayerNorm.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.0.intermediate.dense.weight has shape torch.Size([3072, 768])\n",
      "model.roberta.encoder.layer.0.intermediate.dense.bias has shape torch.Size([3072])\n",
      "model.roberta.encoder.layer.0.output.dense.weight has shape torch.Size([768, 3072])\n",
      "model.roberta.encoder.layer.0.output.dense.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.0.output.LayerNorm.weight has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.0.output.LayerNorm.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.1.attention.self.query.weight has shape torch.Size([768, 768])\n",
      "model.roberta.encoder.layer.1.attention.self.query.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.1.attention.self.key.weight has shape torch.Size([768, 768])\n",
      "model.roberta.encoder.layer.1.attention.self.key.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.1.attention.self.value.weight has shape torch.Size([768, 768])\n",
      "model.roberta.encoder.layer.1.attention.self.value.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.1.attention.output.dense.weight has shape torch.Size([768, 768])\n",
      "model.roberta.encoder.layer.1.attention.output.dense.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.1.attention.output.LayerNorm.weight has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.1.attention.output.LayerNorm.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.1.intermediate.dense.weight has shape torch.Size([3072, 768])\n",
      "model.roberta.encoder.layer.1.intermediate.dense.bias has shape torch.Size([3072])\n",
      "model.roberta.encoder.layer.1.output.dense.weight has shape torch.Size([768, 3072])\n",
      "model.roberta.encoder.layer.1.output.dense.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.1.output.LayerNorm.weight has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.1.output.LayerNorm.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.2.attention.self.query.weight has shape torch.Size([768, 768])\n",
      "model.roberta.encoder.layer.2.attention.self.query.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.2.attention.self.key.weight has shape torch.Size([768, 768])\n",
      "model.roberta.encoder.layer.2.attention.self.key.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.2.attention.self.value.weight has shape torch.Size([768, 768])\n",
      "model.roberta.encoder.layer.2.attention.self.value.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.2.attention.output.dense.weight has shape torch.Size([768, 768])\n",
      "model.roberta.encoder.layer.2.attention.output.dense.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.2.attention.output.LayerNorm.weight has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.2.attention.output.LayerNorm.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.2.intermediate.dense.weight has shape torch.Size([3072, 768])\n",
      "model.roberta.encoder.layer.2.intermediate.dense.bias has shape torch.Size([3072])\n",
      "model.roberta.encoder.layer.2.output.dense.weight has shape torch.Size([768, 3072])\n",
      "model.roberta.encoder.layer.2.output.dense.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.2.output.LayerNorm.weight has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.2.output.LayerNorm.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.3.attention.self.query.weight has shape torch.Size([768, 768])\n",
      "model.roberta.encoder.layer.3.attention.self.query.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.3.attention.self.key.weight has shape torch.Size([768, 768])\n",
      "model.roberta.encoder.layer.3.attention.self.key.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.3.attention.self.value.weight has shape torch.Size([768, 768])\n",
      "model.roberta.encoder.layer.3.attention.self.value.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.3.attention.output.dense.weight has shape torch.Size([768, 768])\n",
      "model.roberta.encoder.layer.3.attention.output.dense.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.3.attention.output.LayerNorm.weight has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.3.attention.output.LayerNorm.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.3.intermediate.dense.weight has shape torch.Size([3072, 768])\n",
      "model.roberta.encoder.layer.3.intermediate.dense.bias has shape torch.Size([3072])\n",
      "model.roberta.encoder.layer.3.output.dense.weight has shape torch.Size([768, 3072])\n",
      "model.roberta.encoder.layer.3.output.dense.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.3.output.LayerNorm.weight has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.3.output.LayerNorm.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.4.attention.self.query.weight has shape torch.Size([768, 768])\n",
      "model.roberta.encoder.layer.4.attention.self.query.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.4.attention.self.key.weight has shape torch.Size([768, 768])\n",
      "model.roberta.encoder.layer.4.attention.self.key.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.4.attention.self.value.weight has shape torch.Size([768, 768])\n",
      "model.roberta.encoder.layer.4.attention.self.value.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.4.attention.output.dense.weight has shape torch.Size([768, 768])\n",
      "model.roberta.encoder.layer.4.attention.output.dense.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.4.attention.output.LayerNorm.weight has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.4.attention.output.LayerNorm.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.4.intermediate.dense.weight has shape torch.Size([3072, 768])\n",
      "model.roberta.encoder.layer.4.intermediate.dense.bias has shape torch.Size([3072])\n",
      "model.roberta.encoder.layer.4.output.dense.weight has shape torch.Size([768, 3072])\n",
      "model.roberta.encoder.layer.4.output.dense.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.4.output.LayerNorm.weight has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.4.output.LayerNorm.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.5.attention.self.query.weight has shape torch.Size([768, 768])\n",
      "model.roberta.encoder.layer.5.attention.self.query.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.5.attention.self.key.weight has shape torch.Size([768, 768])\n",
      "model.roberta.encoder.layer.5.attention.self.key.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.5.attention.self.value.weight has shape torch.Size([768, 768])\n",
      "model.roberta.encoder.layer.5.attention.self.value.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.5.attention.output.dense.weight has shape torch.Size([768, 768])\n",
      "model.roberta.encoder.layer.5.attention.output.dense.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.5.attention.output.LayerNorm.weight has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.5.attention.output.LayerNorm.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.5.intermediate.dense.weight has shape torch.Size([3072, 768])\n",
      "model.roberta.encoder.layer.5.intermediate.dense.bias has shape torch.Size([3072])\n",
      "model.roberta.encoder.layer.5.output.dense.weight has shape torch.Size([768, 3072])\n",
      "model.roberta.encoder.layer.5.output.dense.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.5.output.LayerNorm.weight has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.5.output.LayerNorm.bias has shape torch.Size([768])\n",
      "model.lm_head.bias has shape torch.Size([767])\n",
      "model.lm_head.dense.weight has shape torch.Size([768, 768])\n",
      "model.lm_head.dense.bias has shape torch.Size([768])\n",
      "model.lm_head.layer_norm.weight has shape torch.Size([768])\n",
      "model.lm_head.layer_norm.bias has shape torch.Size([768])\n",
      "final_layers.layer1.weight has shape torch.Size([512, 512])\n",
      "final_layers.layer1.bias has shape torch.Size([512])\n",
      "final_layers.layernorm1.weight has shape torch.Size([512])\n",
      "final_layers.layernorm1.bias has shape torch.Size([512])\n",
      "final_layers.layer2.weight has shape torch.Size([3, 843])\n",
      "final_layers.layer2.bias has shape torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "from src.team5.models.custom_model import CustomChemBERTaModel\n",
    "\n",
    "MS_model = CustomChemBERTaModel(model, MAX_FRAGMENTS, MAX_SEQ_LENGTH, SUPPLEMENTARY_DATA_DIM)\n",
    "\n",
    "print(MS_model)\n",
    "\n",
    "for name, param in MS_model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"{name} has shape {param.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IDwMMYCaYAZK"
   },
   "source": [
    "# LoRA config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "y0PF6-qGZ683"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 413,668 || all params: 44,786,119 || trainable%: 0.9237\n",
      "base_model.model.model.roberta.encoder.layer.0.attention.self.query.lora_A.default.weight is trainable\n",
      "base_model.model.model.roberta.encoder.layer.0.attention.self.query.lora_B.default.weight is trainable\n",
      "base_model.model.model.roberta.encoder.layer.0.attention.self.value.lora_A.default.weight is trainable\n",
      "base_model.model.model.roberta.encoder.layer.0.attention.self.value.lora_B.default.weight is trainable\n",
      "base_model.model.model.roberta.encoder.layer.1.attention.self.query.lora_A.default.weight is trainable\n",
      "base_model.model.model.roberta.encoder.layer.1.attention.self.query.lora_B.default.weight is trainable\n",
      "base_model.model.model.roberta.encoder.layer.1.attention.self.value.lora_A.default.weight is trainable\n",
      "base_model.model.model.roberta.encoder.layer.1.attention.self.value.lora_B.default.weight is trainable\n",
      "base_model.model.model.roberta.encoder.layer.2.attention.self.query.lora_A.default.weight is trainable\n",
      "base_model.model.model.roberta.encoder.layer.2.attention.self.query.lora_B.default.weight is trainable\n",
      "base_model.model.model.roberta.encoder.layer.2.attention.self.value.lora_A.default.weight is trainable\n",
      "base_model.model.model.roberta.encoder.layer.2.attention.self.value.lora_B.default.weight is trainable\n",
      "base_model.model.model.roberta.encoder.layer.3.attention.self.query.lora_A.default.weight is trainable\n",
      "base_model.model.model.roberta.encoder.layer.3.attention.self.query.lora_B.default.weight is trainable\n",
      "base_model.model.model.roberta.encoder.layer.3.attention.self.value.lora_A.default.weight is trainable\n",
      "base_model.model.model.roberta.encoder.layer.3.attention.self.value.lora_B.default.weight is trainable\n",
      "base_model.model.model.roberta.encoder.layer.4.attention.self.query.lora_A.default.weight is trainable\n",
      "base_model.model.model.roberta.encoder.layer.4.attention.self.query.lora_B.default.weight is trainable\n",
      "base_model.model.model.roberta.encoder.layer.4.attention.self.value.lora_A.default.weight is trainable\n",
      "base_model.model.model.roberta.encoder.layer.4.attention.self.value.lora_B.default.weight is trainable\n",
      "base_model.model.model.roberta.encoder.layer.5.attention.self.query.lora_A.default.weight is trainable\n",
      "base_model.model.model.roberta.encoder.layer.5.attention.self.query.lora_B.default.weight is trainable\n",
      "base_model.model.model.roberta.encoder.layer.5.attention.self.value.lora_A.default.weight is trainable\n",
      "base_model.model.model.roberta.encoder.layer.5.attention.self.value.lora_B.default.weight is trainable\n",
      "base_model.model.final_layers.modules_to_save.default.layer1.weight is trainable\n",
      "base_model.model.final_layers.modules_to_save.default.layer1.bias is trainable\n",
      "base_model.model.final_layers.modules_to_save.default.layernorm1.weight is trainable\n",
      "base_model.model.final_layers.modules_to_save.default.layernorm1.bias is trainable\n",
      "base_model.model.final_layers.modules_to_save.default.layer2.weight is trainable\n",
      "base_model.model.final_layers.modules_to_save.default.layer2.bias is trainable\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=[\"query\", \"value\"],\n",
    "    modules_to_save=[\n",
    "        \"final_layers\"\n",
    "    ],  # change this to the name of the new modules at the end.\n",
    "    bias=\"none\",\n",
    ")\n",
    "\n",
    "peft_model = get_peft_model(MS_model, peft_config)\n",
    "\n",
    "peft_model.print_trainable_parameters()  # check that it's training the right things\n",
    "for name, param in peft_model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"{name} is trainable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-q-zpo0kaF0p"
   },
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "import torch.nn as nn\n",
    "from transformers import TrainerCallback\n",
    "\n",
    "class ProfilingCallback(TrainerCallback):\n",
    "    def __init__(self, device, n_steps=10):\n",
    "        self.device = device\n",
    "        self.n_steps = n_steps\n",
    "\n",
    "    def on_step_end(self, args, state, control, **kwargs):\n",
    "        if state.global_step % self.n_steps == 0:\n",
    "            with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "                         profile_memory=True, record_shapes=True) as prof:\n",
    "                with record_function(\"model_inference\"):\n",
    "                    # Run a forward pass\n",
    "                    example = train_dataset[0]\n",
    "                    # Each field in the example is a tensor, so we need to add a batch dimension to the front of each\n",
    "                    example = {k: v.unsqueeze(0).to(self.device) for k, v in example.items()}\n",
    "                    peft_model(**example)\n",
    "            \n",
    "            print(f\"Step {state.global_step}\")\n",
    "            print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=20))\n",
    "            print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=20))\n",
    "            print(prof.key_averages().table(sort_by=\"cpu_memory_usage\", row_limit=20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 934,746\n",
      "  Num Epochs = 16\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 233,696\n",
      "  Number of trainable parameters = 413,668\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "Could not log the number of model parameters in Weights & Biases due to an AttributeError.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128037' max='233696' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128037/233696 15:42:24 < 12:57:42, 2.26 it/s, Epoch 8.77/16]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2191</td>\n",
       "      <td>126.641700</td>\n",
       "      <td>223.470978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4382</td>\n",
       "      <td>64.741700</td>\n",
       "      <td>70.331215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6573</td>\n",
       "      <td>50.842800</td>\n",
       "      <td>56.329411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8764</td>\n",
       "      <td>31.601800</td>\n",
       "      <td>45.029770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10955</td>\n",
       "      <td>28.990800</td>\n",
       "      <td>43.254875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13146</td>\n",
       "      <td>32.315700</td>\n",
       "      <td>33.861061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15337</td>\n",
       "      <td>26.151300</td>\n",
       "      <td>32.509182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17528</td>\n",
       "      <td>23.750700</td>\n",
       "      <td>30.418785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19719</td>\n",
       "      <td>21.354500</td>\n",
       "      <td>24.332491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21910</td>\n",
       "      <td>21.996900</td>\n",
       "      <td>20.955444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24101</td>\n",
       "      <td>18.161000</td>\n",
       "      <td>22.761475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26292</td>\n",
       "      <td>18.103800</td>\n",
       "      <td>21.568752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28483</td>\n",
       "      <td>18.982400</td>\n",
       "      <td>19.653883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30674</td>\n",
       "      <td>18.793000</td>\n",
       "      <td>20.262465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32865</td>\n",
       "      <td>16.476800</td>\n",
       "      <td>17.121439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35056</td>\n",
       "      <td>17.346500</td>\n",
       "      <td>19.275679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37247</td>\n",
       "      <td>15.195200</td>\n",
       "      <td>18.401253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39438</td>\n",
       "      <td>15.406300</td>\n",
       "      <td>16.862686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41629</td>\n",
       "      <td>14.778200</td>\n",
       "      <td>17.585110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43820</td>\n",
       "      <td>15.254100</td>\n",
       "      <td>15.660444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46011</td>\n",
       "      <td>13.495100</td>\n",
       "      <td>16.144897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48202</td>\n",
       "      <td>13.833700</td>\n",
       "      <td>14.416164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50393</td>\n",
       "      <td>13.726000</td>\n",
       "      <td>15.037396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52584</td>\n",
       "      <td>14.766100</td>\n",
       "      <td>15.148789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54775</td>\n",
       "      <td>31.381500</td>\n",
       "      <td>16.071455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56966</td>\n",
       "      <td>13.782600</td>\n",
       "      <td>14.536268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59157</td>\n",
       "      <td>12.535500</td>\n",
       "      <td>14.008674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61348</td>\n",
       "      <td>13.214400</td>\n",
       "      <td>13.417313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63539</td>\n",
       "      <td>12.615600</td>\n",
       "      <td>13.562646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65730</td>\n",
       "      <td>12.171700</td>\n",
       "      <td>12.993809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67921</td>\n",
       "      <td>13.280400</td>\n",
       "      <td>12.802560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70112</td>\n",
       "      <td>11.912800</td>\n",
       "      <td>13.104072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72303</td>\n",
       "      <td>11.691000</td>\n",
       "      <td>13.314528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74494</td>\n",
       "      <td>10.945100</td>\n",
       "      <td>12.200380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76685</td>\n",
       "      <td>11.452100</td>\n",
       "      <td>11.962905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78876</td>\n",
       "      <td>12.468600</td>\n",
       "      <td>13.093219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81067</td>\n",
       "      <td>11.439300</td>\n",
       "      <td>12.224886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83258</td>\n",
       "      <td>11.447100</td>\n",
       "      <td>12.336400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85449</td>\n",
       "      <td>11.452200</td>\n",
       "      <td>12.694394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87640</td>\n",
       "      <td>10.948800</td>\n",
       "      <td>11.780524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89831</td>\n",
       "      <td>11.554800</td>\n",
       "      <td>11.804110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92022</td>\n",
       "      <td>11.052600</td>\n",
       "      <td>11.509710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94213</td>\n",
       "      <td>11.095200</td>\n",
       "      <td>11.924099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96404</td>\n",
       "      <td>10.289000</td>\n",
       "      <td>11.101120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98595</td>\n",
       "      <td>10.419600</td>\n",
       "      <td>11.492403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100786</td>\n",
       "      <td>10.433400</td>\n",
       "      <td>11.169251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102977</td>\n",
       "      <td>10.644200</td>\n",
       "      <td>10.828176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105168</td>\n",
       "      <td>10.203200</td>\n",
       "      <td>11.115779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107359</td>\n",
       "      <td>9.885900</td>\n",
       "      <td>10.780904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109550</td>\n",
       "      <td>10.593500</td>\n",
       "      <td>10.678068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111741</td>\n",
       "      <td>10.230800</td>\n",
       "      <td>10.664813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113932</td>\n",
       "      <td>12.063700</td>\n",
       "      <td>10.638062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116123</td>\n",
       "      <td>9.731300</td>\n",
       "      <td>10.413407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118314</td>\n",
       "      <td>10.105300</td>\n",
       "      <td>10.525187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120505</td>\n",
       "      <td>105.382300</td>\n",
       "      <td>10.710213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122696</td>\n",
       "      <td>10.149300</td>\n",
       "      <td>10.484350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124887</td>\n",
       "      <td>10.035200</td>\n",
       "      <td>10.568341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127078</td>\n",
       "      <td>9.763500</td>\n",
       "      <td>10.364217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 103861\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../logs/training_2024-10-14-20-45-12/checkpoint-2191\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 103861\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../logs/training_2024-10-14-20-45-12/checkpoint-4382\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 103861\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../logs/training_2024-10-14-20-45-12/checkpoint-6573\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 103861\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../logs/training_2024-10-14-20-45-12/checkpoint-8764\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 103861\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../logs/training_2024-10-14-20-45-12/checkpoint-10955\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 103861\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../logs/training_2024-10-14-20-45-12/checkpoint-13146\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 103861\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../logs/training_2024-10-14-20-45-12/checkpoint-15337\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 103861\n",
      "  Batch size = 64\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 103861\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../logs/training_2024-10-14-20-45-12/checkpoint-19719\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 103861\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../logs/training_2024-10-14-20-45-12/checkpoint-24101\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 103861\n",
      "  Batch size = 64\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 103861\n",
      "  Batch size = 64\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 103861\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../logs/training_2024-10-14-20-45-12/checkpoint-37247\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Saving model checkpoint to ../logs/training_2024-10-14-20-45-12/checkpoint-39438\n",
      "Saving model checkpoint to ../logs/training_2024-10-14-20-45-12/checkpoint-61348\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 103861\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../logs/training_2024-10-14-20-45-12/checkpoint-67921\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 103861\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../logs/training_2024-10-14-20-45-12/checkpoint-76685\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 103861\n",
      "  Batch size = 64\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 103861\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../logs/training_2024-10-14-20-45-12/checkpoint-113932\n"
     ]
    }
   ],
   "source": [
    "from datetime import date, datetime\n",
    "import os\n",
    "from transformers import TrainingArguments\n",
    "import torch\n",
    "from transformers import Trainer\n",
    "import transformers\n",
    "\n",
    "transformers.logging.set_verbosity_info()\n",
    "\n",
    "device_type = \"cpu\"\n",
    "if torch.backends.mps.is_available():\n",
    "    device_type = \"mps\"\n",
    "elif torch.cuda.is_available():\n",
    "    device_type = \"cuda\"\n",
    "print(f\"Using device: {device_type}\")\n",
    "device = torch.device(device_type)\n",
    "peft_model.to(device)\n",
    "for param in peft_model.parameters():\n",
    "    param.data = param.data.to(device)\n",
    "\n",
    "if ENABLE_PROFILING:\n",
    "    # Print where each tensor is placed\n",
    "    for name, param in peft_model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            print(f\"{name} is placed on {param.device}\")\n",
    "\n",
    "# Enable logging to wandb if WANDB_API_KEY is set\n",
    "wandb_enabled = os.getenv(\"WANDB_API_KEY\") is not None\n",
    "wandb_api_key = os.getenv(\"WANDB_API_KEY\", None)\n",
    "os.environ[\"WANDB_PROJECT\"] = \"hackathon\"\n",
    "os.environ[\"WANDB_LOG_MODEL\"] = \"end\"\n",
    "os.environ[\"WANDB_WATCH\"] = \"false\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "        output_dir=f\"../logs/training_{date.today().strftime('%Y-%m-%d')}-{datetime.now().strftime('%H-%M-%S')}\",\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    dataloader_num_workers=8,\n",
    "    learning_rate=5e-4,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    logging_steps=0.001 * (3./float(NUM_EPOCHS)),\n",
    "    eval_steps=0.05 * (3./float(NUM_EPOCHS)),\n",
    "    save_steps=0.05 * (3./float(NUM_EPOCHS)),\n",
    "    label_names=[\"labels\"],\n",
    "    report_to=\"wandb\" if wandb_enabled else \"none\",\n",
    "    auto_find_batch_size=(device_type == \"cuda\"),\n",
    "    use_mps_device=(device_type == \"mps\"),\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "callbacks = []\n",
    "if ENABLE_PROFILING:\n",
    "    callbacks.append(ProfilingCallback(device, n_steps=10))\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
