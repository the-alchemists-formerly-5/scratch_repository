{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matchms in /usr/local/lib/python3.11/dist-packages (0.27.0)\n",
      "Requirement already satisfied: deprecated>=1.2.14 in /usr/local/lib/python3.11/dist-packages (from matchms) (1.2.14)\n",
      "Requirement already satisfied: lxml<5.0.0,>=4.9.3 in /usr/local/lib/python3.11/dist-packages (from matchms) (4.9.4)\n",
      "Requirement already satisfied: matplotlib>=3.7 in /usr/local/lib/python3.11/dist-packages (from matchms) (3.9.2)\n",
      "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from matchms) (3.2.1)\n",
      "Requirement already satisfied: numba<0.60,>=0.57.1 in /usr/local/lib/python3.11/dist-packages (from matchms) (0.59.1)\n",
      "Requirement already satisfied: numpy<1.27,>1.22 in /usr/local/lib/python3.11/dist-packages (from matchms) (1.26.4)\n",
      "Requirement already satisfied: pandas>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from matchms) (2.2.3)\n",
      "Requirement already satisfied: pickydict>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from matchms) (0.5.0)\n",
      "Requirement already satisfied: pillow!=9.4.0 in /usr/local/lib/python3.11/dist-packages (from matchms) (10.4.0)\n",
      "Requirement already satisfied: pubchempy in /usr/local/lib/python3.11/dist-packages (from matchms) (1.0.4)\n",
      "Requirement already satisfied: pyteomics>=4.6 in /usr/local/lib/python3.11/dist-packages (from matchms) (4.7.4)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from matchms) (6.0.2)\n",
      "Requirement already satisfied: rdkit>=2023.9.6 in /usr/local/lib/python3.11/dist-packages (from matchms) (2024.3.5)\n",
      "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from matchms) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.11 in /usr/local/lib/python3.11/dist-packages (from matchms) (1.14.1)\n",
      "Requirement already satisfied: sparsestack>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from matchms) (0.5.0)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from matchms) (4.66.5)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.14->matchms) (1.16.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7->matchms) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7->matchms) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7->matchms) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7->matchms) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7->matchms) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7->matchms) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7->matchms) (2.9.0.post0)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba<0.60,>=0.57.1->matchms) (0.42.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.3->matchms) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.3->matchms) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->matchms) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->matchms) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->matchms) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->matchms) (2024.8.30)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7->matchms) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install matchms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/usr/lib/python311.zip', '/usr/lib/python3.11', '/usr/lib/python3.11/lib-dynload', '', '/usr/local/lib/python3.11/dist-packages', '/workspace/scratch_repository/src', '/usr/lib/python3/dist-packages', '/workspace/scratch_repository']\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "DATASET = os.getenv(\"DATASET\", \"../../enveda_library_subset.parquet\")\n",
    "BASE_MODEL = \"seyonec/ChemBERTa-zinc-base-v1\"\n",
    "MAX_FRAGMENTS = 512 # from anton, max number of mzs/intensities\n",
    "MAX_SEQ_LENGTH = 512 # base model max seq length\n",
    "SUPPLEMENTARY_DATA_DIM = 81\n",
    "ENABLE_PROFILING = False # If turned on, will profile the training\n",
    "BATCH_SIZE = int(os.getenv(\"BATCH_SIZE\", 64)) # Note: if using CUDA, it'll automatically find the optimal batch size\n",
    "NUM_EPOCHS = int(os.getenv(\"NUM_EPOCHS\", 16))\n",
    "## Set WANDB_API_KEY environment variable to enable logging to wandb\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "os.environ[\"WANDB_API_KEY\"] = \"69f075ac6ff5b82fb8e32313942465d0a23c6ead\"\n",
    "\n",
    "import sys\n",
    "sys.path.append('/workspace/scratch_repository')\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tYhe3fk-sblS"
   },
   "source": [
    "# Messing around with ChemBERTa for fun and for education\n",
    "\n",
    "The first half of this colab is just fun experiments trying to understand ChemBERTa and it's tokenizer better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420,
     "referenced_widgets": [
      "09447f7d805a456a8d9df123079fef9b",
      "491c2c5348da4cebb59112f76ff21867",
      "fe9ba8c3b518443ba11fd1e700dd2c24",
      "017803aafcb84942bd04ae4b6014d713",
      "7bb64ec2bc31458fac09dafbafc66030",
      "48ba3adb18ee45b085dcfcc74b8e4d19",
      "90c266cbe71d46aaade3ab541889fe07",
      "ed10bed1b375495cb383786278b88953",
      "0186504a6df04889965a532aeaa3058c",
      "9365963655bf4a6f9f65418af1213afb",
      "e8e0cfd2025e41cfb5ea102586988b28",
      "6b54217022de4316a071ee63832b77fe",
      "3cf79467e3384aeba7e957596b912e29",
      "d23dd09659b9428f8cc8083f44e04709",
      "a75c8346a8f74f43941aa43700e6b2d8",
      "e5968c80140b4a71978dbb453ee75af2",
      "285f3c7db7d448a7a9ed62b2f9324e53",
      "e02702dc96744f0bb3304606cfa29e24",
      "5810f7fa342f4543834d8274abe552f5",
      "433bfc6fb35a4199b1cedfbaf5f5a15e",
      "8d37ac015a0f4caebf5455c7c16284dc",
      "f3084e63613741098216632a5f92ef98",
      "1b99d732290a4190982895ff640ea719",
      "b284f3ac0854497fbab925eeb1ded0df",
      "01638020753146678ee0a7692603b6c2",
      "6cd3e39a24fa4ed490ea0567c51c6eee",
      "e0c994de1d654e92ac91d661932ebdfa",
      "2fa221bf24cb4bdf9695b5f593b0d818",
      "502de19d537d41a7b151ca5798f46a72",
      "b689e92305ae4b6693991b37e894f4a0",
      "50e84fe3afd94297a3f198d0dfc4654b",
      "dcc379d6713f47529ea18e30482cfa29",
      "6d6719e9bdcc411c95f60201ee37119a",
      "ec2a4d26292d4606bdcee5c2a0ea5f70",
      "cf7c0c5e780145cf90de13cd375c1cce",
      "6cc566ec625c4251908f083a4ac5e972",
      "ea2e9aa05204487fa884178986a59380",
      "6ff00156a8d1407e8a03899aede36f60",
      "57196d402589425baba759c1f92b3fee",
      "931340e0216b4cdd940a7041f14b62f1",
      "ccba3a5e8f3f4f08b79e5cad740b78b8",
      "f762dd67830c45a1b8725313b92346e4",
      "bc455b59103e4404b9f9b124d6999b3c",
      "d178a1d70c32435482c10d6824bf4131",
      "7de2b548546d4c58b4e1af83cdf618e7",
      "b5c94d24b105493796b8f70d4adb55a7",
      "be8b9e625b624ad89abb785ffdb352b9",
      "7f60ccd803d8490f990a58518b1aa4dd",
      "038ff99e2ffc4f7db7ecd54333a3d71e",
      "177f0b132f2f40b9b63a048635f0dc70",
      "47da5e41d88d4bc6bfb496adacddba30",
      "604c8bed2d6f4c04bb9ae2b78c6f4aea",
      "c83d02b54fe94d6889aae124641f43eb",
      "4df1d8407ea74a3193426b27a15eeaa9",
      "67e3bc2be1034a73be1fc0b3b97da027",
      "f53b7a64750849d18bb4df54237a1110",
      "f7b208a676664b59a90d7d38293df4dd",
      "504f51d204af44b7915060072ea359b2",
      "1f2793e435b04dc7b9502f643a98d533",
      "c9e22b771e9e49ad8354902723d9b951",
      "201c3ab1ff3a46128961e12e4edb2a01",
      "bd46618a5bce46ec840bae0adb001564",
      "ac00b65c79fc4b73a3e2d9d437001e3f",
      "d9c52550dcb8430a891ada649a35d5de",
      "4a99e037f63b4dbfa9d2f58912c46167",
      "f89668c6b88c4bad853403c95eed4fff"
     ]
    },
    "id": "KPjZH305wYrn",
    "outputId": "a36beb4d-b472-44c7-aed8-c200e1cc515c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at seyonec/ChemBERTa-zinc-base-v1 were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import (AutoModelForMaskedLM, AutoTokenizer)\n",
    "\n",
    "model = AutoModelForMaskedLM.from_pretrained(BASE_MODEL)\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y_cMXHTFeMOy"
   },
   "source": [
    "# Data prep\n",
    "\n",
    "\n",
    "These are the columns in the data set:\n",
    "\n",
    "precursor_mz - f64\n",
    "precursor_charge - f64\n",
    "mzs - list[f64]\n",
    "intensities - list[f64]\n",
    "in_silico - bool\n",
    "smiles - str\n",
    "adduct - str\n",
    "collision_energy - str\n",
    "instrument_type - str\n",
    "compound_class - str\n",
    "entropy - f64\n",
    "scaffold_smiles - str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "nyTWxIYveLsl",
    "outputId": "b83c7ecc-b236-47ff-9062-4dcb1e3db1f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 12)\n",
      "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬──────────┬───────────┐\n",
      "│ precursor ┆ precursor ┆ mzs       ┆ intensiti ┆ … ┆ instrumen ┆ compound_ ┆ entropy  ┆ scaffold_ │\n",
      "│ _mz       ┆ _charge   ┆ ---       ┆ es        ┆   ┆ t_type    ┆ class     ┆ ---      ┆ smiles    │\n",
      "│ ---       ┆ ---       ┆ list[f64] ┆ ---       ┆   ┆ ---       ┆ ---       ┆ f64      ┆ ---       │\n",
      "│ f64       ┆ f64       ┆           ┆ list[f64] ┆   ┆ str       ┆ str       ┆          ┆ str       │\n",
      "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪══════════╪═══════════╡\n",
      "│ 401.41417 ┆ 1.0       ┆ [41.03858 ┆ [0.333233 ┆ … ┆ cfm-predi ┆ Cholestan ┆ 3.83767  ┆ C1CCC2C(C │\n",
      "│ 8         ┆           ┆ ,         ┆ ,         ┆   ┆ ct 4      ┆ e         ┆          ┆ 1)CCC1C3C │\n",
      "│           ┆           ┆ 43.05423, ┆ 0.555207, ┆   ┆           ┆ steroids  ┆          ┆ CCC3CCC21 │\n",
      "│           ┆           ┆ …         ┆ …         ┆   ┆           ┆           ┆          ┆           │\n",
      "│           ┆           ┆ 401.414…  ┆ 0.82529…  ┆   ┆           ┆           ┆          ┆           │\n",
      "│ 399.39962 ┆ -1.0      ┆ [69.07097 ┆ [0.0043,  ┆ … ┆ cfm-predi ┆ Cholestan ┆ 1.254399 ┆ C1CCC2C(C │\n",
      "│ 6         ┆           ┆ ,         ┆ 0.005967, ┆   ┆ ct 4      ┆ e         ┆          ┆ 1)CCC1C3C │\n",
      "│           ┆           ┆ 71.08662, ┆ … 1.0]    ┆   ┆           ┆ steroids  ┆          ┆ CCC3CCC21 │\n",
      "│           ┆           ┆ …         ┆           ┆   ┆           ┆           ┆          ┆           │\n",
      "│           ┆           ┆ 399.399…  ┆           ┆   ┆           ┆           ┆          ┆           │\n",
      "│ 331.19148 ┆ -1.0      ┆ [41.00329 ┆ [0.47981, ┆ … ┆ cfm-predi ┆ Amphilect ┆ 3.67856  ┆ O=C1C2=C( │\n",
      "│ 3         ┆           ┆ ,         ┆ 0.126161, ┆   ┆ ct 4      ┆ ane diter ┆          ┆ COC2)CC2C │\n",
      "│           ┆           ┆ 43.01894, ┆ … 1.0]    ┆   ┆           ┆ penoids   ┆          ┆ CCC12     │\n",
      "│           ┆           ┆ …         ┆           ┆   ┆           ┆           ┆          ┆           │\n",
      "│           ┆           ┆ 331.191…  ┆           ┆   ┆           ┆           ┆          ┆           │\n",
      "│ 333.20603 ┆ 1.0       ┆ [39.02293 ┆ [0.740212 ┆ … ┆ cfm-predi ┆ Amphilect ┆ 4.451389 ┆ O=C1C2=C( │\n",
      "│ 5         ┆           ┆ ,         ┆ ,         ┆   ┆ ct 4      ┆ ane diter ┆          ┆ COC2)CC2C │\n",
      "│           ┆           ┆ 41.00219, ┆ 0.008716, ┆   ┆           ┆ penoids   ┆          ┆ CCC12     │\n",
      "│           ┆           ┆ …         ┆ … 1.0]    ┆   ┆           ┆           ┆          ┆           │\n",
      "│           ┆           ┆ 333.206…  ┆           ┆   ┆           ┆           ┆          ┆           │\n",
      "│ 209.11722 ┆ 1.0       ┆ [27.02293 ┆ [0.001363 ┆ … ┆ cfm-predi ┆ 2-pyrone  ┆ 3.94053  ┆ O=c1cccco │\n",
      "│           ┆           ┆ ,         ┆ ,         ┆   ┆ ct 4      ┆ derivativ ┆          ┆ 1         │\n",
      "│           ┆           ┆ 29.03858, ┆ 0.014949, ┆   ┆           ┆ es        ┆          ┆           │\n",
      "│           ┆           ┆ …         ┆ …         ┆   ┆           ┆           ┆          ┆           │\n",
      "│           ┆           ┆ 209.117…  ┆ 0.70399…  ┆   ┆           ┆           ┆          ┆           │\n",
      "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴──────────┴───────────┘\n",
      "['tokenized_smiles', 'attention_mask', 'padded_mzs', 'padded_intensities', 'supplementary_data']\n",
      "['tokenized_smiles', 'attention_mask', 'padded_mzs', 'padded_intensities', 'supplementary_data']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "from src.team5.data.data_loader import SMILESDataset\n",
    "from src.team5.data.data_split import sort_dataframe_by_scaffold, split_dataframe\n",
    "from src.team5.data.prepare import tensorize, prepare_data\n",
    "\n",
    "# Load the data in all the chunk files into one df\n",
    "\n",
    "# List of parquet chunk files\n",
    "chunk_files = [f\"../../chunk_{i}.parquet\" for i in range(1,105)]  \n",
    "\n",
    "# Read and concatenate all parquet files\n",
    "df = pl.concat([pl.read_parquet(file) for file in chunk_files])\n",
    "\n",
    "# Now df contains all data\n",
    "print(df.head())\n",
    "\n",
    "# Sort by scaffold\n",
    "df_sorted = sort_dataframe_by_scaffold(df)\n",
    "\n",
    "# Split the dataframe into train and test\n",
    "df_train, df_test = split_dataframe(df_sorted, split_ratio=0.9)\n",
    "\n",
    "# Prepare the training and testing data (this step creates 'padded_mzs' and other columns)\n",
    "df_train_prepared = prepare_data(df_train)\n",
    "df_test_prepared = prepare_data(df_test)\n",
    "\n",
    "# Check column names to ensure 'padded_mzs' is included\n",
    "print(df_train_prepared.columns)\n",
    "print(df_test_prepared.columns)\n",
    "\n",
    "# Run tensorization on prepared data\n",
    "(train_tokenized_smiles, train_attention_mask, train_labels, train_supplementary_data) = tensorize(df_train_prepared, split=\"train\")\n",
    "(test_tokenized_smiles, test_attention_mask, test_labels, test_supplementary_data) = tensorize(df_test_prepared, split=\"test\")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = SMILESDataset(train_tokenized_smiles, train_attention_mask, train_labels, train_supplementary_data)\n",
    "test_dataset = SMILESDataset(test_tokenized_smiles, test_attention_mask, test_labels, test_supplementary_data)\n",
    "\n",
    "# Calculate total steps\n",
    "total_steps = len(train_dataset) // BATCH_SIZE * NUM_EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print({k:v.dtype for k,v in train_dataset[0].items()})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fENovYIHeaOO"
   },
   "source": [
    "# Custom model for our problem\n",
    "This is probably the most important part in terms of design choices. We are changing the ChemBERTa model by adding on something at the end. This new module will take the hidden SMILES embedding from the last hidden layer as input. It will also take in all the other data about the precusor molecule and experimental conditions (eg, precusor mz, collison energy etc). For now, let's call that supplementary data.\n",
    "\n",
    "I've written the simplest possible thing here: a single linear layer that takes the embedding of the entire seq, concatinated with all the supplementary data for the example. It outputs \"labels\", which is mzs and intensities zipped together.\n",
    "\n",
    "The reason for making a single module output both mzs and intensities is because there needs to be the same number of fragments per example, and the two numbers are very related.\n",
    "\n",
    "A single linear layer is probably a terrible choice though, since this is the only layer that sees all the supplementary data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "rMogXqZteZ1Z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomChemBERTaModel(\n",
      "  (model): RobertaForMaskedLM(\n",
      "    (roberta): RobertaModel(\n",
      "      (embeddings): RobertaEmbeddings(\n",
      "        (word_embeddings): Embedding(767, 768, padding_idx=1)\n",
      "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "        (token_type_embeddings): Embedding(1, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): RobertaEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0-5): 6 x RobertaLayer(\n",
      "            (attention): RobertaAttention(\n",
      "              (self): RobertaSdpaSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): RobertaSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): RobertaIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): RobertaOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (lm_head): RobertaLMHead(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (decoder): Linear(in_features=768, out_features=767, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (final_layers): FinalLayers(\n",
      "    (layer1): Linear(in_features=81, out_features=768, bias=True)\n",
      "    (activation1): ReLU()\n",
      "    (dropout1): Dropout(p=0.1, inplace=False)\n",
      "    (layernorm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (cross_attention): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "    )\n",
      "    (self_attention): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "    )\n",
      "    (output_linear): Linear(in_features=768, out_features=3, bias=True)\n",
      "    (dropout2): Dropout(p=0.1, inplace=False)\n",
      "    (activation2): ReLU()\n",
      "  )\n",
      ")\n",
      "model.roberta.embeddings.word_embeddings.weight has shape torch.Size([767, 768])\n",
      "model.roberta.embeddings.position_embeddings.weight has shape torch.Size([514, 768])\n",
      "model.roberta.embeddings.token_type_embeddings.weight has shape torch.Size([1, 768])\n",
      "model.roberta.embeddings.LayerNorm.weight has shape torch.Size([768])\n",
      "model.roberta.embeddings.LayerNorm.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.0.attention.self.query.weight has shape torch.Size([768, 768])\n",
      "model.roberta.encoder.layer.0.attention.self.query.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.0.attention.self.key.weight has shape torch.Size([768, 768])\n",
      "model.roberta.encoder.layer.0.attention.self.key.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.0.attention.self.value.weight has shape torch.Size([768, 768])\n",
      "model.roberta.encoder.layer.0.attention.self.value.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.0.attention.output.dense.weight has shape torch.Size([768, 768])\n",
      "model.roberta.encoder.layer.0.attention.output.dense.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.0.attention.output.LayerNorm.weight has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.0.attention.output.LayerNorm.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.0.intermediate.dense.weight has shape torch.Size([3072, 768])\n",
      "model.roberta.encoder.layer.0.intermediate.dense.bias has shape torch.Size([3072])\n",
      "model.roberta.encoder.layer.0.output.dense.weight has shape torch.Size([768, 3072])\n",
      "model.roberta.encoder.layer.0.output.dense.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.0.output.LayerNorm.weight has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.0.output.LayerNorm.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.1.attention.self.query.weight has shape torch.Size([768, 768])\n",
      "model.roberta.encoder.layer.1.attention.self.query.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.1.attention.self.key.weight has shape torch.Size([768, 768])\n",
      "model.roberta.encoder.layer.1.attention.self.key.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.1.attention.self.value.weight has shape torch.Size([768, 768])\n",
      "model.roberta.encoder.layer.1.attention.self.value.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.1.attention.output.dense.weight has shape torch.Size([768, 768])\n",
      "model.roberta.encoder.layer.1.attention.output.dense.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.1.attention.output.LayerNorm.weight has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.1.attention.output.LayerNorm.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.1.intermediate.dense.weight has shape torch.Size([3072, 768])\n",
      "model.roberta.encoder.layer.1.intermediate.dense.bias has shape torch.Size([3072])\n",
      "model.roberta.encoder.layer.1.output.dense.weight has shape torch.Size([768, 3072])\n",
      "model.roberta.encoder.layer.1.output.dense.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.1.output.LayerNorm.weight has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.1.output.LayerNorm.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.2.attention.self.query.weight has shape torch.Size([768, 768])\n",
      "model.roberta.encoder.layer.2.attention.self.query.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.2.attention.self.key.weight has shape torch.Size([768, 768])\n",
      "model.roberta.encoder.layer.2.attention.self.key.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.2.attention.self.value.weight has shape torch.Size([768, 768])\n",
      "model.roberta.encoder.layer.2.attention.self.value.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.2.attention.output.dense.weight has shape torch.Size([768, 768])\n",
      "model.roberta.encoder.layer.2.attention.output.dense.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.2.attention.output.LayerNorm.weight has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.2.attention.output.LayerNorm.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.2.intermediate.dense.weight has shape torch.Size([3072, 768])\n",
      "model.roberta.encoder.layer.2.intermediate.dense.bias has shape torch.Size([3072])\n",
      "model.roberta.encoder.layer.2.output.dense.weight has shape torch.Size([768, 3072])\n",
      "model.roberta.encoder.layer.2.output.dense.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.2.output.LayerNorm.weight has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.2.output.LayerNorm.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.3.attention.self.query.weight has shape torch.Size([768, 768])\n",
      "model.roberta.encoder.layer.3.attention.self.query.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.3.attention.self.key.weight has shape torch.Size([768, 768])\n",
      "model.roberta.encoder.layer.3.attention.self.key.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.3.attention.self.value.weight has shape torch.Size([768, 768])\n",
      "model.roberta.encoder.layer.3.attention.self.value.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.3.attention.output.dense.weight has shape torch.Size([768, 768])\n",
      "model.roberta.encoder.layer.3.attention.output.dense.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.3.attention.output.LayerNorm.weight has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.3.attention.output.LayerNorm.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.3.intermediate.dense.weight has shape torch.Size([3072, 768])\n",
      "model.roberta.encoder.layer.3.intermediate.dense.bias has shape torch.Size([3072])\n",
      "model.roberta.encoder.layer.3.output.dense.weight has shape torch.Size([768, 3072])\n",
      "model.roberta.encoder.layer.3.output.dense.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.3.output.LayerNorm.weight has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.3.output.LayerNorm.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.4.attention.self.query.weight has shape torch.Size([768, 768])\n",
      "model.roberta.encoder.layer.4.attention.self.query.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.4.attention.self.key.weight has shape torch.Size([768, 768])\n",
      "model.roberta.encoder.layer.4.attention.self.key.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.4.attention.self.value.weight has shape torch.Size([768, 768])\n",
      "model.roberta.encoder.layer.4.attention.self.value.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.4.attention.output.dense.weight has shape torch.Size([768, 768])\n",
      "model.roberta.encoder.layer.4.attention.output.dense.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.4.attention.output.LayerNorm.weight has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.4.attention.output.LayerNorm.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.4.intermediate.dense.weight has shape torch.Size([3072, 768])\n",
      "model.roberta.encoder.layer.4.intermediate.dense.bias has shape torch.Size([3072])\n",
      "model.roberta.encoder.layer.4.output.dense.weight has shape torch.Size([768, 3072])\n",
      "model.roberta.encoder.layer.4.output.dense.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.4.output.LayerNorm.weight has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.4.output.LayerNorm.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.5.attention.self.query.weight has shape torch.Size([768, 768])\n",
      "model.roberta.encoder.layer.5.attention.self.query.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.5.attention.self.key.weight has shape torch.Size([768, 768])\n",
      "model.roberta.encoder.layer.5.attention.self.key.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.5.attention.self.value.weight has shape torch.Size([768, 768])\n",
      "model.roberta.encoder.layer.5.attention.self.value.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.5.attention.output.dense.weight has shape torch.Size([768, 768])\n",
      "model.roberta.encoder.layer.5.attention.output.dense.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.5.attention.output.LayerNorm.weight has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.5.attention.output.LayerNorm.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.5.intermediate.dense.weight has shape torch.Size([3072, 768])\n",
      "model.roberta.encoder.layer.5.intermediate.dense.bias has shape torch.Size([3072])\n",
      "model.roberta.encoder.layer.5.output.dense.weight has shape torch.Size([768, 3072])\n",
      "model.roberta.encoder.layer.5.output.dense.bias has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.5.output.LayerNorm.weight has shape torch.Size([768])\n",
      "model.roberta.encoder.layer.5.output.LayerNorm.bias has shape torch.Size([768])\n",
      "model.lm_head.bias has shape torch.Size([767])\n",
      "model.lm_head.dense.weight has shape torch.Size([768, 768])\n",
      "model.lm_head.dense.bias has shape torch.Size([768])\n",
      "model.lm_head.layer_norm.weight has shape torch.Size([768])\n",
      "model.lm_head.layer_norm.bias has shape torch.Size([768])\n",
      "final_layers.layer1.weight has shape torch.Size([768, 81])\n",
      "final_layers.layer1.bias has shape torch.Size([768])\n",
      "final_layers.layernorm1.weight has shape torch.Size([768])\n",
      "final_layers.layernorm1.bias has shape torch.Size([768])\n",
      "final_layers.cross_attention.in_proj_weight has shape torch.Size([2304, 768])\n",
      "final_layers.cross_attention.in_proj_bias has shape torch.Size([2304])\n",
      "final_layers.cross_attention.out_proj.weight has shape torch.Size([768, 768])\n",
      "final_layers.cross_attention.out_proj.bias has shape torch.Size([768])\n",
      "final_layers.self_attention.in_proj_weight has shape torch.Size([2304, 768])\n",
      "final_layers.self_attention.in_proj_bias has shape torch.Size([2304])\n",
      "final_layers.self_attention.out_proj.weight has shape torch.Size([768, 768])\n",
      "final_layers.self_attention.out_proj.bias has shape torch.Size([768])\n",
      "final_layers.output_linear.weight has shape torch.Size([3, 768])\n",
      "final_layers.output_linear.bias has shape torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "from src.team5.models.custom_model import CustomChemBERTaModel\n",
    "\n",
    "MS_model = CustomChemBERTaModel(model, MAX_FRAGMENTS, MAX_SEQ_LENGTH, SUPPLEMENTARY_DATA_DIM)\n",
    "\n",
    "print(MS_model)\n",
    "\n",
    "for name, param in MS_model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"{name} has shape {param.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IDwMMYCaYAZK"
   },
   "source": [
    "# LoRA config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "y0PF6-qGZ683"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 4,939,011 || all params: 53,836,805 || trainable%: 9.1740\n",
      "base_model.model.model.roberta.encoder.layer.0.attention.self.query.lora_A.default.weight is trainable\n",
      "base_model.model.model.roberta.encoder.layer.0.attention.self.query.lora_B.default.weight is trainable\n",
      "base_model.model.model.roberta.encoder.layer.0.attention.self.value.lora_A.default.weight is trainable\n",
      "base_model.model.model.roberta.encoder.layer.0.attention.self.value.lora_B.default.weight is trainable\n",
      "base_model.model.model.roberta.encoder.layer.1.attention.self.query.lora_A.default.weight is trainable\n",
      "base_model.model.model.roberta.encoder.layer.1.attention.self.query.lora_B.default.weight is trainable\n",
      "base_model.model.model.roberta.encoder.layer.1.attention.self.value.lora_A.default.weight is trainable\n",
      "base_model.model.model.roberta.encoder.layer.1.attention.self.value.lora_B.default.weight is trainable\n",
      "base_model.model.model.roberta.encoder.layer.2.attention.self.query.lora_A.default.weight is trainable\n",
      "base_model.model.model.roberta.encoder.layer.2.attention.self.query.lora_B.default.weight is trainable\n",
      "base_model.model.model.roberta.encoder.layer.2.attention.self.value.lora_A.default.weight is trainable\n",
      "base_model.model.model.roberta.encoder.layer.2.attention.self.value.lora_B.default.weight is trainable\n",
      "base_model.model.model.roberta.encoder.layer.3.attention.self.query.lora_A.default.weight is trainable\n",
      "base_model.model.model.roberta.encoder.layer.3.attention.self.query.lora_B.default.weight is trainable\n",
      "base_model.model.model.roberta.encoder.layer.3.attention.self.value.lora_A.default.weight is trainable\n",
      "base_model.model.model.roberta.encoder.layer.3.attention.self.value.lora_B.default.weight is trainable\n",
      "base_model.model.model.roberta.encoder.layer.4.attention.self.query.lora_A.default.weight is trainable\n",
      "base_model.model.model.roberta.encoder.layer.4.attention.self.query.lora_B.default.weight is trainable\n",
      "base_model.model.model.roberta.encoder.layer.4.attention.self.value.lora_A.default.weight is trainable\n",
      "base_model.model.model.roberta.encoder.layer.4.attention.self.value.lora_B.default.weight is trainable\n",
      "base_model.model.model.roberta.encoder.layer.5.attention.self.query.lora_A.default.weight is trainable\n",
      "base_model.model.model.roberta.encoder.layer.5.attention.self.query.lora_B.default.weight is trainable\n",
      "base_model.model.model.roberta.encoder.layer.5.attention.self.value.lora_A.default.weight is trainable\n",
      "base_model.model.model.roberta.encoder.layer.5.attention.self.value.lora_B.default.weight is trainable\n",
      "base_model.model.final_layers.modules_to_save.default.layer1.weight is trainable\n",
      "base_model.model.final_layers.modules_to_save.default.layer1.bias is trainable\n",
      "base_model.model.final_layers.modules_to_save.default.layernorm1.weight is trainable\n",
      "base_model.model.final_layers.modules_to_save.default.layernorm1.bias is trainable\n",
      "base_model.model.final_layers.modules_to_save.default.cross_attention.in_proj_weight is trainable\n",
      "base_model.model.final_layers.modules_to_save.default.cross_attention.in_proj_bias is trainable\n",
      "base_model.model.final_layers.modules_to_save.default.cross_attention.out_proj.weight is trainable\n",
      "base_model.model.final_layers.modules_to_save.default.cross_attention.out_proj.bias is trainable\n",
      "base_model.model.final_layers.modules_to_save.default.self_attention.in_proj_weight is trainable\n",
      "base_model.model.final_layers.modules_to_save.default.self_attention.in_proj_bias is trainable\n",
      "base_model.model.final_layers.modules_to_save.default.self_attention.out_proj.weight is trainable\n",
      "base_model.model.final_layers.modules_to_save.default.self_attention.out_proj.bias is trainable\n",
      "base_model.model.final_layers.modules_to_save.default.output_linear.weight is trainable\n",
      "base_model.model.final_layers.modules_to_save.default.output_linear.bias is trainable\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=[\"query\", \"value\"],\n",
    "    modules_to_save=[\n",
    "        \"final_layers\"\n",
    "    ],  # change this to the name of the new modules at the end.\n",
    "    bias=\"none\",\n",
    ")\n",
    "\n",
    "peft_model = get_peft_model(MS_model, peft_config)\n",
    "\n",
    "peft_model.print_trainable_parameters()  # check that it's training the right things\n",
    "for name, param in peft_model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"{name} is trainable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-q-zpo0kaF0p"
   },
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "import torch.nn as nn\n",
    "from transformers import TrainerCallback\n",
    "\n",
    "# def compute_metrics(pred):\n",
    "#     \"\"\"\n",
    "#     Custom metric function to calculate greedy cosine and hungarian cosine.\n",
    "#     \"\"\"\n",
    "#     labels = pred.label_ids\n",
    "#     preds = pred.predictions\n",
    "\n",
    "#     # Assuming your model outputs spectra with m/z and intensities\n",
    "#     mz_a = preds['mz']  # Predicted m/z values\n",
    "#     intensities_a = preds['intensities']  # Predicted intensities\n",
    "#     mz_b = labels['mz']  # Ground truth m/z values\n",
    "#     intensities_b = labels['intensities']  # Ground truth intensities\n",
    "\n",
    "#     # Use the custom model's evaluate_spectra method to compute metrics\n",
    "#     metrics = peft_model.evaluate_spectra(mz_a, mz_b, intensities_a, intensities_b)\n",
    "\n",
    "#     return metrics\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    # Assuming predictions is a tuple (pred_mz, pred_probs, pred_flags)\n",
    "    # and labels is a tuple (mz_true, intensities_true)\n",
    "    \n",
    "    # Create an instance of your model to use evaluate_spectra\n",
    "    \n",
    "    # Use the evaluate_spectra method from your model\n",
    "    metrics = peft_model.evaluate_spectra(predictions, labels)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "class ProfilingCallback(TrainerCallback):\n",
    "    def __init__(self, device, n_steps=10):\n",
    "        self.device = device\n",
    "        self.n_steps = n_steps\n",
    "\n",
    "    def on_step_end(self, args, state, control, **kwargs):\n",
    "        if state.global_step % self.n_steps == 0:\n",
    "            with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "                         profile_memory=True, record_shapes=True) as prof:\n",
    "                with record_function(\"model_inference\"):\n",
    "                    # Run a forward pass\n",
    "                    example = train_dataset[0]\n",
    "                    # Each field in the example is a tensor, so we need to add a batch dimension to the front of each\n",
    "                    example = {k: v.unsqueeze(0).to(self.device) for k, v in example.items()}\n",
    "                    peft_model(**example)\n",
    "            \n",
    "            print(f\"Step {state.global_step}\")\n",
    "            print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=20))\n",
    "            print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=20))\n",
    "            print(prof.key_averages().table(sort_by=\"cpu_memory_usage\", row_limit=20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 934,746\n",
      "  Num Epochs = 16\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 233,696\n",
      "  Number of trainable parameters = 266,212\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mteam5-hackathonbio\u001b[0m (\u001b[33mteam5-hackathon-bio\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/scratch_repository/notebooks/wandb/run-20241016_221730-hj04okl3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/team5-hackathon-bio/hackathon/runs/hj04okl3' target=\"_blank\">../logs/training_2024-10-16-22-17-29</a></strong> to <a href='https://wandb.ai/team5-hackathon-bio/hackathon' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/team5-hackathon-bio/hackathon' target=\"_blank\">https://wandb.ai/team5-hackathon-bio/hackathon</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/team5-hackathon-bio/hackathon/runs/hj04okl3' target=\"_blank\">https://wandb.ai/team5-hackathon-bio/hackathon/runs/hj04okl3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not log the number of model parameters in Weights & Biases due to an AttributeError.\n",
      "Exception ignored in: <function _releaseLock at 0x7f15be166f20>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.11/logging/__init__.py\", line 237, in _releaseLock\n",
      "    def _releaseLock():\n",
      "    \n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 25434, 25497, 25560, 25623) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:1131\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1130\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1131\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "File \u001b[0;32m/usr/lib/python3.11/queue.py:179\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_empty\u001b[38;5;241m.\u001b[39mwait(remaining)\n",
      "\u001b[0;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 64\u001b[0m\n\u001b[1;32m     53\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(ProfilingCallback(device, n_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m     55\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     56\u001b[0m     model\u001b[38;5;241m=\u001b[39mpeft_model,\n\u001b[1;32m     57\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     61\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 64\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py:2052\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2050\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2051\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2052\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2054\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2056\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2057\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/utils/memory.py:157\u001b[0m, in \u001b[0;36mfind_executable_batch_size.<locals>.decorator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo executable batch size found, reached zero.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_reduce_batch_size(e):\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py:2345\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2342\u001b[0m     rng_to_sync \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2344\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 2345\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   2346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtotal_batched_samples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m   2348\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minclude_num_input_tokens_seen\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/data_loader.py:550\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;66;03m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 550\u001b[0m     current_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:1327\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1327\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1330\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:1283\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1281\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m   1282\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m-> 1283\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1284\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1285\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:1144\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1143\u001b[0m     pids_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(w\u001b[38;5;241m.\u001b[39mpid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[0;32m-> 1144\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpids_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) exited unexpectedly\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue\u001b[38;5;241m.\u001b[39mEmpty):\n\u001b[1;32m   1146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 25434, 25497, 25560, 25623) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "from datetime import date, datetime\n",
    "import os\n",
    "from transformers import TrainingArguments\n",
    "import torch\n",
    "from transformers import Trainer\n",
    "import transformers\n",
    "\n",
    "transformers.logging.set_verbosity_info()\n",
    "\n",
    "# Check for available GPUs\n",
    "num_gpus = torch.cuda.device_count()\n",
    "if num_gpus > 1:\n",
    "    print(f\"Using DataParallel with {num_gpus} GPUs\")\n",
    "    device_type = \"cuda\"\n",
    "    use_data_parallel = True\n",
    "elif torch.cuda.is_available():\n",
    "    print(\"Using a single GPU\")\n",
    "    device_type = \"cuda\"\n",
    "    use_data_parallel = False\n",
    "elif torch.backends.mps.is_available():\n",
    "    print(\"Using MPS (Metal Performance Shaders)\")\n",
    "    device_type = \"mps\"\n",
    "    use_data_parallel = False\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "    device_type = \"cpu\"\n",
    "    use_data_parallel = False\n",
    "\n",
    "device = torch.device(device_type)\n",
    "\n",
    "# Move model to device and wrap with DataParallel if applicable\n",
    "peft_model = peft_model.to(device)\n",
    "if use_data_parallel:\n",
    "    peft_model = torch.nn.DataParallel(peft_model)\n",
    "\n",
    "# Ensure all parameters are on the correct device\n",
    "for param in peft_model.parameters():\n",
    "    param.data = param.data.to(device)\n",
    "\n",
    "if ENABLE_PROFILING:\n",
    "    # Print where each tensor is placed\n",
    "    for name, param in peft_model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            print(f\"{name} is placed on {param.device}\")\n",
    "\n",
    "# Enable logging to wandb if WANDB_API_KEY is set\n",
    "wandb_enabled = os.getenv(\"WANDB_API_KEY\") is not None\n",
    "wandb_api_key = os.getenv(\"WANDB_API_KEY\", None)\n",
    "os.environ[\"WANDB_PROJECT\"] = \"hackathon\"\n",
    "os.environ[\"WANDB_LOG_MODEL\"] = \"end\"\n",
    "os.environ[\"WANDB_WATCH\"] = \"false\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "        output_dir=f\"../logs/training_{date.today().strftime('%Y-%m-%d')}-{datetime.now().strftime('%H-%M-%S')}\",\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    dataloader_num_workers=8,\n",
    "    learning_rate=5e-4,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    logging_steps=0.001 * (3./float(NUM_EPOCHS)),\n",
    "    eval_steps=0.05 * (3./float(NUM_EPOCHS)),\n",
    "    save_steps=0.05 * (3./float(NUM_EPOCHS)),\n",
    "    label_names=[\"labels\"],\n",
    "    report_to=\"wandb\" if wandb_enabled else \"none\",\n",
    "    auto_find_batch_size=(device_type == \"cuda\"),\n",
    "    use_mps_device=(device_type == \"mps\"),\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "callbacks = []\n",
    "if ENABLE_PROFILING:\n",
    "    callbacks.append(ProfilingCallback(device, n_steps=10))\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference on trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "import torch\n",
    "\n",
    "CHECKPOINT = '../logs/training_2024-10-14-20-45-12/checkpoint-233696'\n",
    "\n",
    "peft_model = PeftModel.from_pretrained(MS_model, CHECKPOINT)\n",
    "peft_model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "peft_model = peft_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from src.team5.data.prepare import interleave\n",
    "from src.team5.models.custom_model import process_predicted_output, calculate_loss\n",
    "from itertools import chain\n",
    "\n",
    "def perform_inference(peft_model, tokenizer, smiles, input_ids, supplementary_data, attention_mask, labels=None):\n",
    "    # Print non-tokenized input\n",
    "    # print(f\"Input SMILES: {smiles}\")\n",
    "    # print(f\"Supplementary data: {supplementary_data}\")\n",
    "    # print()\n",
    "\n",
    "    # Tokenize SMILES\n",
    "    tokenized = tokenizer.encode(smiles, padding=\"max_length\")\n",
    "    assert input_ids.tolist() == tokenized, f'input_ids: {input_ids}, tokenized: {tokenized}'\n",
    "\n",
    "    # Prepare input data\n",
    "    input_data = {\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': attention_mask,\n",
    "        'supplementary_data': supplementary_data,\n",
    "        'labels': labels\n",
    "    }\n",
    "\n",
    "    # Move input data to the same device as the model\n",
    "    device = next(peft_model.parameters()).device\n",
    "    input_data = {k: v.unsqueeze(0).to(device) for k, v in input_data.items()}\n",
    "\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        loss, predicted_output = peft_model(**input_data)\n",
    "        mzs, probs = process_predicted_output(predicted_output)\n",
    "\n",
    "    # Process and print the output\n",
    "    processed_output = process_output(mzs, probs) \n",
    "    print(f\"processed_output: {processed_output}\")\n",
    "    # print(f\"Loss: {loss}\")\n",
    "\n",
    "\n",
    "    # Print label if provided\n",
    "    if labels is not None:\n",
    "        print(f\"True label: {labels.tolist()}\")\n",
    "\n",
    "def process_output(mzs, probs):\n",
    "    mzs = mzs.squeeze().cpu().numpy()\n",
    "    probs = probs.squeeze().cpu().numpy()\n",
    "    return interleave({'mzs': mzs, 'intensities': probs})\n",
    "\n",
    "def run_model(dataset_example, tokenized_example):\n",
    "    return perform_inference(peft_model, tokenizer, dataset_example['smiles'][0], tokenized_example['input_ids'], tokenized_example['supplementary_data'], tokenized_example['attention_mask'], labels=tokenized_example['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x75 and 512x512)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m453\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mrun_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[23], line 50\u001b[0m, in \u001b[0;36mrun_model\u001b[0;34m(dataset_example, tokenized_example)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_model\u001b[39m(dataset_example, tokenized_example):\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mperform_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpeft_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_example\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msmiles\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenized_example\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenized_example\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msupplementary_data\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenized_example\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenized_example\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[23], line 31\u001b[0m, in \u001b[0;36mperform_inference\u001b[0;34m(peft_model, tokenizer, smiles, input_ids, supplementary_data, attention_mask, labels)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Perform inference\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 31\u001b[0m     loss, predicted_output \u001b[38;5;241m=\u001b[39m \u001b[43mpeft_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     mzs, probs \u001b[38;5;241m=\u001b[39m process_predicted_output(predicted_output)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Process and print the output\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/peft/peft_model.py:812\u001b[0m, in \u001b[0;36mPeftModel.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_peft_forward_hooks(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    811\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspecial_peft_forward_args}\n\u001b[0;32m--> 812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_base_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/scratch_repository/src/team5/models/custom_model.py:176\u001b[0m, in \u001b[0;36mCustomChemBERTaModel.forward\u001b[0;34m(self, input_ids, attention_mask, supplementary_data, labels)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;66;03m# Extract last hidden state (embeddings)\u001b[39;00m\n\u001b[1;32m    174\u001b[0m last_hidden_state \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mhidden_states[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]  \n\u001b[0;32m--> 176\u001b[0m predicted_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinal_layers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlast_hidden_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msupplementary_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Shape: [batch_size, max_fragments, 3]\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# Schedule sigma from 1.0 to 0.0001 over the course of 100000 steps\u001b[39;00m\n\u001b[1;32m    179\u001b[0m sigma \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.0001\u001b[39m) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m100000\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/peft/utils/other.py:333\u001b[0m, in \u001b[0;36mModulesToSaveWrapper.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moriginal_module(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m adapter_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 333\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodules_to_save\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactive_adapter\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mixed_batch_forward(x, \u001b[38;5;241m*\u001b[39margs, adapter_names\u001b[38;5;241m=\u001b[39madapter_names, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/scratch_repository/src/team5/models/custom_model.py:44\u001b[0m, in \u001b[0;36mFinalLayers.forward\u001b[0;34m(self, x, supplementary_data, attention_mask)\u001b[0m\n\u001b[1;32m     41\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m*\u001b[39m expanded_mask  \u001b[38;5;66;03m# Zero out padding tokens\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Process supplementary data to match hidden_size\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m supplementary_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer1\u001b[49m\u001b[43m(\u001b[49m\u001b[43msupplementary_data\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Shape: (batch_size, hidden_size)\u001b[39;00m\n\u001b[1;32m     45\u001b[0m supplementary_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(supplementary_data)\n\u001b[1;32m     46\u001b[0m supplementary_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayernorm1(supplementary_data)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x75 and 512x512)"
     ]
    }
   ],
   "source": [
    "idx = 453\n",
    "run_model(df_test[idx], test_dataset[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
