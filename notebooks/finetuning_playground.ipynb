{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"../data/raw/enveda_library_subset_10percent.parquet\"\n",
    "BASE_MODEL = \"seyonec/ChemBERTa-zinc-base-v1\"\n",
    "MAX_FRAGMENTS = 512 # from anton, max number of mzs/intensities\n",
    "MAX_SEQ_LENGTH = 1024 # from anton, max length of SMILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tYhe3fk-sblS"
   },
   "source": [
    "# Messing around with ChemBERTa for fun and for education\n",
    "\n",
    "The first half of this colab is just fun experiments trying to understand ChemBERTa and it's tokenizer better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420,
     "referenced_widgets": [
      "09447f7d805a456a8d9df123079fef9b",
      "491c2c5348da4cebb59112f76ff21867",
      "fe9ba8c3b518443ba11fd1e700dd2c24",
      "017803aafcb84942bd04ae4b6014d713",
      "7bb64ec2bc31458fac09dafbafc66030",
      "48ba3adb18ee45b085dcfcc74b8e4d19",
      "90c266cbe71d46aaade3ab541889fe07",
      "ed10bed1b375495cb383786278b88953",
      "0186504a6df04889965a532aeaa3058c",
      "9365963655bf4a6f9f65418af1213afb",
      "e8e0cfd2025e41cfb5ea102586988b28",
      "6b54217022de4316a071ee63832b77fe",
      "3cf79467e3384aeba7e957596b912e29",
      "d23dd09659b9428f8cc8083f44e04709",
      "a75c8346a8f74f43941aa43700e6b2d8",
      "e5968c80140b4a71978dbb453ee75af2",
      "285f3c7db7d448a7a9ed62b2f9324e53",
      "e02702dc96744f0bb3304606cfa29e24",
      "5810f7fa342f4543834d8274abe552f5",
      "433bfc6fb35a4199b1cedfbaf5f5a15e",
      "8d37ac015a0f4caebf5455c7c16284dc",
      "f3084e63613741098216632a5f92ef98",
      "1b99d732290a4190982895ff640ea719",
      "b284f3ac0854497fbab925eeb1ded0df",
      "01638020753146678ee0a7692603b6c2",
      "6cd3e39a24fa4ed490ea0567c51c6eee",
      "e0c994de1d654e92ac91d661932ebdfa",
      "2fa221bf24cb4bdf9695b5f593b0d818",
      "502de19d537d41a7b151ca5798f46a72",
      "b689e92305ae4b6693991b37e894f4a0",
      "50e84fe3afd94297a3f198d0dfc4654b",
      "dcc379d6713f47529ea18e30482cfa29",
      "6d6719e9bdcc411c95f60201ee37119a",
      "ec2a4d26292d4606bdcee5c2a0ea5f70",
      "cf7c0c5e780145cf90de13cd375c1cce",
      "6cc566ec625c4251908f083a4ac5e972",
      "ea2e9aa05204487fa884178986a59380",
      "6ff00156a8d1407e8a03899aede36f60",
      "57196d402589425baba759c1f92b3fee",
      "931340e0216b4cdd940a7041f14b62f1",
      "ccba3a5e8f3f4f08b79e5cad740b78b8",
      "f762dd67830c45a1b8725313b92346e4",
      "bc455b59103e4404b9f9b124d6999b3c",
      "d178a1d70c32435482c10d6824bf4131",
      "7de2b548546d4c58b4e1af83cdf618e7",
      "b5c94d24b105493796b8f70d4adb55a7",
      "be8b9e625b624ad89abb785ffdb352b9",
      "7f60ccd803d8490f990a58518b1aa4dd",
      "038ff99e2ffc4f7db7ecd54333a3d71e",
      "177f0b132f2f40b9b63a048635f0dc70",
      "47da5e41d88d4bc6bfb496adacddba30",
      "604c8bed2d6f4c04bb9ae2b78c6f4aea",
      "c83d02b54fe94d6889aae124641f43eb",
      "4df1d8407ea74a3193426b27a15eeaa9",
      "67e3bc2be1034a73be1fc0b3b97da027",
      "f53b7a64750849d18bb4df54237a1110",
      "f7b208a676664b59a90d7d38293df4dd",
      "504f51d204af44b7915060072ea359b2",
      "1f2793e435b04dc7b9502f643a98d533",
      "c9e22b771e9e49ad8354902723d9b951",
      "201c3ab1ff3a46128961e12e4edb2a01",
      "bd46618a5bce46ec840bae0adb001564",
      "ac00b65c79fc4b73a3e2d9d437001e3f",
      "d9c52550dcb8430a891ada649a35d5de",
      "4a99e037f63b4dbfa9d2f58912c46167",
      "f89668c6b88c4bad853403c95eed4fff"
     ]
    },
    "id": "KPjZH305wYrn",
    "outputId": "a36beb4d-b472-44c7-aed8-c200e1cc515c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at seyonec/ChemBERTa-zinc-base-v1 were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import (AutoModelForMaskedLM, AutoTokenizer, RobertaModel,\n",
    "                          RobertaTokenizer, pipeline)\n",
    "\n",
    "model = AutoModelForMaskedLM.from_pretrained(BASE_MODEL)\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y_cMXHTFeMOy"
   },
   "source": [
    "# Data prep\n",
    "\n",
    "\n",
    "These are the columns in the data set:\n",
    "\n",
    "precursor_mz - f64\n",
    "precursor_charge - f64\n",
    "mzs - list[f64]\n",
    "intensities - list[f64]\n",
    "in_silico - bool\n",
    "smiles - str\n",
    "adduct - str\n",
    "collision_energy - str\n",
    "instrument_type - str\n",
    "compound_class - str\n",
    "entropy - f64\n",
    "scaffold_smiles - str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "nyTWxIYveLsl",
    "outputId": "b83c7ecc-b236-47ff-9062-4dcb1e3db1f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['precursor_mz', 'precursor_charge', 'mzs', 'intensities', 'in_silico',\n",
      "       'smiles', 'adduct', 'collision_energy', 'instrument_type',\n",
      "       'compound_class', 'entropy', 'scaffold_smiles'],\n",
      "      dtype='object')\n",
      "Index(['precursor_mz', 'precursor_charge', 'mzs', 'intensities', 'in_silico',\n",
      "       'smiles', 'adduct', 'collision_energy', 'instrument_type',\n",
      "       'compound_class', 'entropy', 'scaffold_smiles'],\n",
      "      dtype='object')\n",
      "   precursor_mz  precursor_charge  \\\n",
      "0    338.139000               1.0   \n",
      "1    243.169998               1.0   \n",
      "2    417.340000               1.0   \n",
      "3    861.283605              -1.0   \n",
      "4    237.110001               1.0   \n",
      "\n",
      "                                                 mzs  \\\n",
      "0  [65.039124, 68.049843, 70.065514, 73.657387, 8...   \n",
      "1  [128.062, 129.033, 141.07, 143.085, 145.028, 1...   \n",
      "2  [98.096001, 99.098999, 399.333008, 417.34201, ...   \n",
      "3  [41.00329, 55.01894, 59.01385, 61.0295, 71.013...   \n",
      "4  [63.02, 63.026, 65.037, 65.043, 69.0, 75.02, 7...   \n",
      "\n",
      "                                         intensities  in_silico  \\\n",
      "0  [0.005384466169514861, 0.0010471983069807872, ...      False   \n",
      "1  [0.005, 0.008, 0.012, 0.01, 0.005, 0.009, 0.27...      False   \n",
      "2                  [0.234, 0.127, 0.101, 1.0, 0.736]      False   \n",
      "3  [0.1306941631375437, 0.003461609280058921, 0.6...       True   \n",
      "4  [0.062, 0.062, 0.062, 0.125, 0.016, 0.031, 0.0...      False   \n",
      "\n",
      "                                              smiles   adduct  \\\n",
      "0          O=c1c(-c2ccccc2)coc2c(CN3CCOCC3)c(O)ccc12   [M+H]+   \n",
      "1                        C=C1CCC2OC2(C)CCC2C1CC2(C)C  [M+Na]+   \n",
      "2  CC1CCC2(OC1)OC1CC3C4CCC5CC(O)CCC5(C)C4CCC3(C)C...   [M+H]+   \n",
      "3  CC1(CC(=O)O)c2cc3nc(cc4[nH]c(cc5[nH]c(cc(n2)C1...   [M-H]-   \n",
      "4                          CCCCC(O)C1CC(OC)=CC(=O)O1  [M+Na]+   \n",
      "\n",
      "  collision_energy instrument_type                  compound_class   entropy  \\\n",
      "0             None        Orbitrap                     Isoflavones  1.967338   \n",
      "1               40        Orbitrap  Caryophyllane sesquiterpenoids  2.399525   \n",
      "2             None        Orbitrap             Spirostane steroids  1.269396   \n",
      "3         10-20-40   cfm-predict 4                            None  2.668707   \n",
      "4               40            QTOF            2-pyrone derivatives  4.108257   \n",
      "\n",
      "                                     scaffold_smiles  \n",
      "0             O=c1c(-c2ccccc2)coc2c(CN3CCOCC3)cccc12  \n",
      "1                               C=C1CCC2OC2CCC2CCC12  \n",
      "2          C1CCC2(CC3C(CC4C3CCC3C5CCCCC5CCC34)O2)OC1  \n",
      "3  C1=CC2=NC1=CC1=NC(=CC3=NC(=Cc4ccc([nH]4)C2)CC3...  \n",
      "4                                        O=C1C=CCCO1  \n",
      "       precursor_mz  precursor_charge  \\\n",
      "93474    240.078600               1.0   \n",
      "93475    341.268636               1.0   \n",
      "93476    409.114014              -1.0   \n",
      "93477    423.166056              -1.0   \n",
      "93478    359.258000               1.0   \n",
      "\n",
      "                                                     mzs  \\\n",
      "93474  [55.0541, 73.0647, 89.0383, 100.0756, 114.0549...   \n",
      "93475  [43.054227, 57.069877, 71.012756, 71.085527, 9...   \n",
      "93476  [50.15293, 50.254989, 50.694215, 50.72023, 50....   \n",
      "93477  [41.00329, 43.01894, 44.9982, 53.00329, 55.018...   \n",
      "93478  [67.054703, 71.049469, 81.070053, 85.064957, 9...   \n",
      "\n",
      "                                             intensities  in_silico  \\\n",
      "93474  [0.00200371, 0.00221331, 0.0020136999999999998...      False   \n",
      "93475  [0.03003003003003003, 0.17317317317317318, 0.0...      False   \n",
      "93476  [0.00015384, 0.0001498, 0.00017282, 0.00013978...      False   \n",
      "93477  [0.042229230314378634, 0.08160047304622055, 0....       True   \n",
      "93478  [0.018053392909529935, 0.020513167693453387, 0...      False   \n",
      "\n",
      "                                                  smiles  adduct  \\\n",
      "93474                         CC1(C)CON(Cc2ccccc2Cl)C1=O  [M+H]+   \n",
      "93475                    CCCCCCCCOC(=O)C=CC(=O)OCCCCCCCC  [M+H]+   \n",
      "93476  COc1cc(-c2c(C)cc(O)cc2OC2OC(CO)C(O)C(O)C2O)oc(...  [M-H]-   \n",
      "93477  CC1=C2C(=O)CC(C)=C2C2OC(=O)C(C)(OC3OC(CO)C(O)C...  [M-H]-   \n",
      "93478  CC(=O)OC1CCC2(C)C(=CCC3C2CCC2(C)C(C(C)=O)CCC32)C1  [M+H]+   \n",
      "\n",
      "      collision_energy instrument_type            compound_class   entropy  \\\n",
      "93474     35 (nominal)     LC-ESI-ITFT                      None  0.707169   \n",
      "93475               20        ESI-QTOF            Wax monoesters  1.297458   \n",
      "93476            35HCD         ESI-QFT      2-pyrone derivatives  2.089564   \n",
      "93477         10-20-40   cfm-predict 4  Guaiane sesquiterpenoids  4.108406   \n",
      "93478             None        Orbitrap         Pregnane steroids  3.165259   \n",
      "\n",
      "                              scaffold_smiles  \n",
      "93474                      O=C1CCON1Cc1ccccc1  \n",
      "93475                                          \n",
      "93476          O=c1cccc(-c2ccccc2OC2CCCCO2)o1  \n",
      "93477  O=C1C=CC2C1=CCCC1C(OC3CCCCO3)C(=O)OC21  \n",
      "93478              C1=C2CCCCC2C2CCC3CCCC3C2C1  \n",
      "93474\n",
      "10386\n"
     ]
    }
   ],
   "source": [
    "# import the data (with pandas?)\n",
    "import pandas as pd\n",
    "\n",
    "## Load the dataset (for some reason this didn't work for me)\n",
    "# df = pd.read_parquet('enveda_library_subset 2.parquet')\n",
    "\n",
    "# print(df.head())\n",
    "\n",
    "\n",
    "# custom Dataset class for all the types of data.\n",
    "# I think we might want to make a new 'column' of data that combines mzs and intensities into \"label\"\n",
    "\n",
    "from src.team5.data.data_loader import SMILESDataset\n",
    "from src.team5.data.data_split import sort_dataframe_by_scaffold, split_dataframe\n",
    "\n",
    "df = pd.read_parquet(DATASET)\n",
    "\n",
    "df_sorted = sort_dataframe_by_scaffold(df)\n",
    "\n",
    "df_train, df_test = split_dataframe(df_sorted, split_ratio=0.9)\n",
    "\n",
    "# Print column names\n",
    "print(df_train.columns)\n",
    "print(df_test.columns)\n",
    "print(df_train.head())\n",
    "print(df_test.head())\n",
    "\n",
    "train_dataset = SMILESDataset(df_train, tokenizer, MAX_SEQ_LENGTH)\n",
    "eval_dataset = SMILESDataset(df_test, tokenizer, MAX_SEQ_LENGTH)\n",
    "\n",
    "# Print length of datasets\n",
    "print(len(train_dataset))\n",
    "print(len(eval_dataset))\n",
    "\n",
    "## batch?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fENovYIHeaOO"
   },
   "source": [
    "# Custom model for our problem\n",
    "This is probably the most important part in terms of design choices. We are changing the ChemBERTa model by adding on something at the end. This new module will take the hidden SMILES embedding from the last hidden layer as input. It will also take in all the other data about the precusor molecule and experimental conditions (eg, precusor mz, collison energy etc). For now, let's call that supplementary data.\n",
    "\n",
    "I've written the simplest possible thing here: a single linear layer that takes the embedding of the entire seq, concatinated with all the supplementary data for the example. It outputs \"labels\", which is mzs and intensities zipped together.\n",
    "\n",
    "The reason for making a single module output both mzs and intensities is because there needs to be the same number of fragments per example, and the two numbers are very related.\n",
    "\n",
    "A single linear layer is probably a terrible choice though, since this is the only layer that sees all the supplementary data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "rMogXqZteZ1Z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomChemBERTaModel(\n",
      "  (model): RobertaForMaskedLM(\n",
      "    (roberta): RobertaModel(\n",
      "      (embeddings): RobertaEmbeddings(\n",
      "        (word_embeddings): Embedding(767, 768, padding_idx=1)\n",
      "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "        (token_type_embeddings): Embedding(1, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): RobertaEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0-5): 6 x RobertaLayer(\n",
      "            (attention): RobertaAttention(\n",
      "              (self): RobertaSdpaSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): RobertaSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): RobertaIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): RobertaOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (lm_head): RobertaLMHead(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (decoder): Linear(in_features=768, out_features=767, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "roberta.embeddings.word_embeddings.weight has shape torch.Size([767, 768])\n",
      "roberta.embeddings.position_embeddings.weight has shape torch.Size([514, 768])\n",
      "roberta.embeddings.token_type_embeddings.weight has shape torch.Size([1, 768])\n",
      "roberta.embeddings.LayerNorm.weight has shape torch.Size([768])\n",
      "roberta.embeddings.LayerNorm.bias has shape torch.Size([768])\n",
      "roberta.encoder.layer.0.attention.self.query.weight has shape torch.Size([768, 768])\n",
      "roberta.encoder.layer.0.attention.self.query.bias has shape torch.Size([768])\n",
      "roberta.encoder.layer.0.attention.self.key.weight has shape torch.Size([768, 768])\n",
      "roberta.encoder.layer.0.attention.self.key.bias has shape torch.Size([768])\n",
      "roberta.encoder.layer.0.attention.self.value.weight has shape torch.Size([768, 768])\n",
      "roberta.encoder.layer.0.attention.self.value.bias has shape torch.Size([768])\n",
      "roberta.encoder.layer.0.attention.output.dense.weight has shape torch.Size([768, 768])\n",
      "roberta.encoder.layer.0.attention.output.dense.bias has shape torch.Size([768])\n",
      "roberta.encoder.layer.0.attention.output.LayerNorm.weight has shape torch.Size([768])\n",
      "roberta.encoder.layer.0.attention.output.LayerNorm.bias has shape torch.Size([768])\n",
      "roberta.encoder.layer.0.intermediate.dense.weight has shape torch.Size([3072, 768])\n",
      "roberta.encoder.layer.0.intermediate.dense.bias has shape torch.Size([3072])\n",
      "roberta.encoder.layer.0.output.dense.weight has shape torch.Size([768, 3072])\n",
      "roberta.encoder.layer.0.output.dense.bias has shape torch.Size([768])\n",
      "roberta.encoder.layer.0.output.LayerNorm.weight has shape torch.Size([768])\n",
      "roberta.encoder.layer.0.output.LayerNorm.bias has shape torch.Size([768])\n",
      "roberta.encoder.layer.1.attention.self.query.weight has shape torch.Size([768, 768])\n",
      "roberta.encoder.layer.1.attention.self.query.bias has shape torch.Size([768])\n",
      "roberta.encoder.layer.1.attention.self.key.weight has shape torch.Size([768, 768])\n",
      "roberta.encoder.layer.1.attention.self.key.bias has shape torch.Size([768])\n",
      "roberta.encoder.layer.1.attention.self.value.weight has shape torch.Size([768, 768])\n",
      "roberta.encoder.layer.1.attention.self.value.bias has shape torch.Size([768])\n",
      "roberta.encoder.layer.1.attention.output.dense.weight has shape torch.Size([768, 768])\n",
      "roberta.encoder.layer.1.attention.output.dense.bias has shape torch.Size([768])\n",
      "roberta.encoder.layer.1.attention.output.LayerNorm.weight has shape torch.Size([768])\n",
      "roberta.encoder.layer.1.attention.output.LayerNorm.bias has shape torch.Size([768])\n",
      "roberta.encoder.layer.1.intermediate.dense.weight has shape torch.Size([3072, 768])\n",
      "roberta.encoder.layer.1.intermediate.dense.bias has shape torch.Size([3072])\n",
      "roberta.encoder.layer.1.output.dense.weight has shape torch.Size([768, 3072])\n",
      "roberta.encoder.layer.1.output.dense.bias has shape torch.Size([768])\n",
      "roberta.encoder.layer.1.output.LayerNorm.weight has shape torch.Size([768])\n",
      "roberta.encoder.layer.1.output.LayerNorm.bias has shape torch.Size([768])\n",
      "roberta.encoder.layer.2.attention.self.query.weight has shape torch.Size([768, 768])\n",
      "roberta.encoder.layer.2.attention.self.query.bias has shape torch.Size([768])\n",
      "roberta.encoder.layer.2.attention.self.key.weight has shape torch.Size([768, 768])\n",
      "roberta.encoder.layer.2.attention.self.key.bias has shape torch.Size([768])\n",
      "roberta.encoder.layer.2.attention.self.value.weight has shape torch.Size([768, 768])\n",
      "roberta.encoder.layer.2.attention.self.value.bias has shape torch.Size([768])\n",
      "roberta.encoder.layer.2.attention.output.dense.weight has shape torch.Size([768, 768])\n",
      "roberta.encoder.layer.2.attention.output.dense.bias has shape torch.Size([768])\n",
      "roberta.encoder.layer.2.attention.output.LayerNorm.weight has shape torch.Size([768])\n",
      "roberta.encoder.layer.2.attention.output.LayerNorm.bias has shape torch.Size([768])\n",
      "roberta.encoder.layer.2.intermediate.dense.weight has shape torch.Size([3072, 768])\n",
      "roberta.encoder.layer.2.intermediate.dense.bias has shape torch.Size([3072])\n",
      "roberta.encoder.layer.2.output.dense.weight has shape torch.Size([768, 3072])\n",
      "roberta.encoder.layer.2.output.dense.bias has shape torch.Size([768])\n",
      "roberta.encoder.layer.2.output.LayerNorm.weight has shape torch.Size([768])\n",
      "roberta.encoder.layer.2.output.LayerNorm.bias has shape torch.Size([768])\n",
      "roberta.encoder.layer.3.attention.self.query.weight has shape torch.Size([768, 768])\n",
      "roberta.encoder.layer.3.attention.self.query.bias has shape torch.Size([768])\n",
      "roberta.encoder.layer.3.attention.self.key.weight has shape torch.Size([768, 768])\n",
      "roberta.encoder.layer.3.attention.self.key.bias has shape torch.Size([768])\n",
      "roberta.encoder.layer.3.attention.self.value.weight has shape torch.Size([768, 768])\n",
      "roberta.encoder.layer.3.attention.self.value.bias has shape torch.Size([768])\n",
      "roberta.encoder.layer.3.attention.output.dense.weight has shape torch.Size([768, 768])\n",
      "roberta.encoder.layer.3.attention.output.dense.bias has shape torch.Size([768])\n",
      "roberta.encoder.layer.3.attention.output.LayerNorm.weight has shape torch.Size([768])\n",
      "roberta.encoder.layer.3.attention.output.LayerNorm.bias has shape torch.Size([768])\n",
      "roberta.encoder.layer.3.intermediate.dense.weight has shape torch.Size([3072, 768])\n",
      "roberta.encoder.layer.3.intermediate.dense.bias has shape torch.Size([3072])\n",
      "roberta.encoder.layer.3.output.dense.weight has shape torch.Size([768, 3072])\n",
      "roberta.encoder.layer.3.output.dense.bias has shape torch.Size([768])\n",
      "roberta.encoder.layer.3.output.LayerNorm.weight has shape torch.Size([768])\n",
      "roberta.encoder.layer.3.output.LayerNorm.bias has shape torch.Size([768])\n",
      "roberta.encoder.layer.4.attention.self.query.weight has shape torch.Size([768, 768])\n",
      "roberta.encoder.layer.4.attention.self.query.bias has shape torch.Size([768])\n",
      "roberta.encoder.layer.4.attention.self.key.weight has shape torch.Size([768, 768])\n",
      "roberta.encoder.layer.4.attention.self.key.bias has shape torch.Size([768])\n",
      "roberta.encoder.layer.4.attention.self.value.weight has shape torch.Size([768, 768])\n",
      "roberta.encoder.layer.4.attention.self.value.bias has shape torch.Size([768])\n",
      "roberta.encoder.layer.4.attention.output.dense.weight has shape torch.Size([768, 768])\n",
      "roberta.encoder.layer.4.attention.output.dense.bias has shape torch.Size([768])\n",
      "roberta.encoder.layer.4.attention.output.LayerNorm.weight has shape torch.Size([768])\n",
      "roberta.encoder.layer.4.attention.output.LayerNorm.bias has shape torch.Size([768])\n",
      "roberta.encoder.layer.4.intermediate.dense.weight has shape torch.Size([3072, 768])\n",
      "roberta.encoder.layer.4.intermediate.dense.bias has shape torch.Size([3072])\n",
      "roberta.encoder.layer.4.output.dense.weight has shape torch.Size([768, 3072])\n",
      "roberta.encoder.layer.4.output.dense.bias has shape torch.Size([768])\n",
      "roberta.encoder.layer.4.output.LayerNorm.weight has shape torch.Size([768])\n",
      "roberta.encoder.layer.4.output.LayerNorm.bias has shape torch.Size([768])\n",
      "roberta.encoder.layer.5.attention.self.query.weight has shape torch.Size([768, 768])\n",
      "roberta.encoder.layer.5.attention.self.query.bias has shape torch.Size([768])\n",
      "roberta.encoder.layer.5.attention.self.key.weight has shape torch.Size([768, 768])\n",
      "roberta.encoder.layer.5.attention.self.key.bias has shape torch.Size([768])\n",
      "roberta.encoder.layer.5.attention.self.value.weight has shape torch.Size([768, 768])\n",
      "roberta.encoder.layer.5.attention.self.value.bias has shape torch.Size([768])\n",
      "roberta.encoder.layer.5.attention.output.dense.weight has shape torch.Size([768, 768])\n",
      "roberta.encoder.layer.5.attention.output.dense.bias has shape torch.Size([768])\n",
      "roberta.encoder.layer.5.attention.output.LayerNorm.weight has shape torch.Size([768])\n",
      "roberta.encoder.layer.5.attention.output.LayerNorm.bias has shape torch.Size([768])\n",
      "roberta.encoder.layer.5.intermediate.dense.weight has shape torch.Size([3072, 768])\n",
      "roberta.encoder.layer.5.intermediate.dense.bias has shape torch.Size([3072])\n",
      "roberta.encoder.layer.5.output.dense.weight has shape torch.Size([768, 3072])\n",
      "roberta.encoder.layer.5.output.dense.bias has shape torch.Size([768])\n",
      "roberta.encoder.layer.5.output.LayerNorm.weight has shape torch.Size([768])\n",
      "roberta.encoder.layer.5.output.LayerNorm.bias has shape torch.Size([768])\n",
      "lm_head.bias has shape torch.Size([767])\n",
      "lm_head.dense.weight has shape torch.Size([768, 768])\n",
      "lm_head.dense.bias has shape torch.Size([768])\n",
      "lm_head.layer_norm.weight has shape torch.Size([768])\n",
      "lm_head.layer_norm.bias has shape torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "from src.team5.models.custom_model import CustomChemBERTaModel\n",
    "\n",
    "MS_model = CustomChemBERTaModel(model, MAX_FRAGMENTS, MAX_SEQ_LENGTH)\n",
    "\n",
    "print(MS_model)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"{name} has shape {param.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IDwMMYCaYAZK"
   },
   "source": [
    "# LoRA config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "y0PF6-qGZ683"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,329,407 || all params: 45,435,646 || trainable%: 2.9259\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=[\"key\", \"query\", \"value\"],\n",
    "    modules_to_save=[\n",
    "        \"lm_head\"\n",
    "    ],  # change this to the name of the new modules at the end.\n",
    "    bias=\"none\",\n",
    ")\n",
    "\n",
    "peft_model = get_peft_model(MS_model, peft_config)\n",
    "\n",
    "peft_model.print_trainable_parameters()  # check that it's training the right things\n",
    "for name, param in peft_model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"{name} is trainable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-q-zpo0kaF0p"
   },
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c074b2eef804a00ba857a9a5b38307a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35055 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'SMILESDataset' object has no attribute 'labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 30\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m metric\u001b[38;5;241m.\u001b[39mcompute(predictions\u001b[38;5;241m=\u001b[39mpredictions, references\u001b[38;5;241m=\u001b[39mlabels)\n\u001b[1;32m     22\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     23\u001b[0m     model\u001b[38;5;241m=\u001b[39mpeft_model,\n\u001b[1;32m     24\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m     28\u001b[0m )\n\u001b[0;32m---> 30\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/scratch_repository/.venv/lib/python3.12/site-packages/transformers/trainer.py:2052\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2050\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2051\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2052\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2054\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2056\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2057\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/scratch_repository/.venv/lib/python3.12/site-packages/transformers/trainer.py:2345\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2342\u001b[0m     rng_to_sync \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2344\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 2345\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   2346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtotal_batched_samples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m   2348\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minclude_num_input_tokens_seen\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m~/workspace/scratch_repository/.venv/lib/python3.12/site-packages/accelerate/data_loader.py:550\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;66;03m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 550\u001b[0m     current_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/scratch_repository/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/workspace/scratch_repository/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/workspace/scratch_repository/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/workspace/scratch_repository/src/team5/data/data_loader.py:50\u001b[0m, in \u001b[0;36mSMILESDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     48\u001b[0m smiles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmiles[idx]\n\u001b[1;32m     49\u001b[0m precursor_mz \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecursor_mz[idx]\n\u001b[0;32m---> 50\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabels\u001b[49m[idx]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Tokenize SMILES\u001b[39;00m\n\u001b[1;32m     53\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(\n\u001b[1;32m     54\u001b[0m     smiles,\n\u001b[1;32m     55\u001b[0m     truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     58\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     59\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SMILESDataset' object has no attribute 'labels'"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from transformers import Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../logs/test_trainer\",\n",
    "    num_train_epochs=3,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=0.1,\n",
    "    label_names=[\"labels\"],\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "I3YvQNVqcGyF"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_collator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AdamW\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[1;32m      4\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[0;32m----> 5\u001b[0m     train_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, collate_fn\u001b[38;5;241m=\u001b[39m\u001b[43mdata_collator\u001b[49m\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m AdamW(peft_model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-5\u001b[39m)\n\u001b[1;32m      9\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_collator' is not defined"
     ]
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=16, shuffle=True, collate_fn=data_collator\n",
    ")\n",
    "optimizer = AdamW(peft_model.parameters(), lr=5e-5)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "peft_model.to(device)\n",
    "peft_model.train()\n",
    "\n",
    "for epoch in range(training_args.num_train_epochs):\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        supplementary_data = batch[\"supplementary_data\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        outputs = peft_model(\n",
    "            input_ids=input_ids, supplementary_data=supplementary_data, labels=labels\n",
    "        )\n",
    "        loss = outputs[1]\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "01jClKYXdZ-Z"
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0FDkmqV7dXNf"
   },
   "outputs": [],
   "source": [
    "def prepare_inference_input(smiles, precursor_mz):\n",
    "    inputs = tokenizer(\n",
    "        smiles,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "    inputs[\"supplementary_data\"] = torch.tensor(\n",
    "        [supplementary_data], dtype=torch.float\n",
    "    ).to(device)\n",
    "    return inputs\n",
    "\n",
    "\n",
    "peft_model.eval()\n",
    "\n",
    "# Example data\n",
    "smiles_example = \"CCO\"\n",
    "supplementary_data_example = 0  # TODO\n",
    "\n",
    "# Prepare input\n",
    "inputs = prepare_inference_input(smiles_example, supplementary_data_example)\n",
    "\n",
    "# Inference\n",
    "with torch.no_grad():\n",
    "    outputs = peft_model(**inputs)\n",
    "    logits = outputs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2D8bfVV9keeM"
   },
   "source": [
    "# Choices that affect the whole architecture\n",
    "\n",
    "*   Format for the supplementary data\n",
    "*   Format for the label data\n",
    "*   The format of the output of the new model\n",
    "\n",
    "\n",
    "\n",
    "### More modular choices (that are important)\n",
    "\n",
    "\n",
    "*   Whether we have to predict compound_class at inference\n",
    "*   Include in_silico data?\n",
    "*   Architeture of the modified ChemBERTa model\n",
    "*   LoRA parameters\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
