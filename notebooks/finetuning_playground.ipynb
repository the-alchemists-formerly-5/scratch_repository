{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "09447f7d805a456a8d9df123079fef9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_491c2c5348da4cebb59112f76ff21867",
              "IPY_MODEL_fe9ba8c3b518443ba11fd1e700dd2c24",
              "IPY_MODEL_017803aafcb84942bd04ae4b6014d713"
            ],
            "layout": "IPY_MODEL_7bb64ec2bc31458fac09dafbafc66030"
          }
        },
        "491c2c5348da4cebb59112f76ff21867": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48ba3adb18ee45b085dcfcc74b8e4d19",
            "placeholder": "​",
            "style": "IPY_MODEL_90c266cbe71d46aaade3ab541889fe07",
            "value": "config.json: 100%"
          }
        },
        "fe9ba8c3b518443ba11fd1e700dd2c24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed10bed1b375495cb383786278b88953",
            "max": 515,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0186504a6df04889965a532aeaa3058c",
            "value": 515
          }
        },
        "017803aafcb84942bd04ae4b6014d713": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9365963655bf4a6f9f65418af1213afb",
            "placeholder": "​",
            "style": "IPY_MODEL_e8e0cfd2025e41cfb5ea102586988b28",
            "value": " 515/515 [00:00&lt;00:00, 8.48kB/s]"
          }
        },
        "7bb64ec2bc31458fac09dafbafc66030": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48ba3adb18ee45b085dcfcc74b8e4d19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90c266cbe71d46aaade3ab541889fe07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed10bed1b375495cb383786278b88953": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0186504a6df04889965a532aeaa3058c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9365963655bf4a6f9f65418af1213afb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8e0cfd2025e41cfb5ea102586988b28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b54217022de4316a071ee63832b77fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3cf79467e3384aeba7e957596b912e29",
              "IPY_MODEL_d23dd09659b9428f8cc8083f44e04709",
              "IPY_MODEL_a75c8346a8f74f43941aa43700e6b2d8"
            ],
            "layout": "IPY_MODEL_e5968c80140b4a71978dbb453ee75af2"
          }
        },
        "3cf79467e3384aeba7e957596b912e29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_285f3c7db7d448a7a9ed62b2f9324e53",
            "placeholder": "​",
            "style": "IPY_MODEL_e02702dc96744f0bb3304606cfa29e24",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "d23dd09659b9428f8cc8083f44e04709": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5810f7fa342f4543834d8274abe552f5",
            "max": 336422980,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_433bfc6fb35a4199b1cedfbaf5f5a15e",
            "value": 336422980
          }
        },
        "a75c8346a8f74f43941aa43700e6b2d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d37ac015a0f4caebf5455c7c16284dc",
            "placeholder": "​",
            "style": "IPY_MODEL_f3084e63613741098216632a5f92ef98",
            "value": " 336M/336M [00:03&lt;00:00, 123MB/s]"
          }
        },
        "e5968c80140b4a71978dbb453ee75af2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "285f3c7db7d448a7a9ed62b2f9324e53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e02702dc96744f0bb3304606cfa29e24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5810f7fa342f4543834d8274abe552f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "433bfc6fb35a4199b1cedfbaf5f5a15e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8d37ac015a0f4caebf5455c7c16284dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3084e63613741098216632a5f92ef98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b99d732290a4190982895ff640ea719": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b284f3ac0854497fbab925eeb1ded0df",
              "IPY_MODEL_01638020753146678ee0a7692603b6c2",
              "IPY_MODEL_6cd3e39a24fa4ed490ea0567c51c6eee"
            ],
            "layout": "IPY_MODEL_e0c994de1d654e92ac91d661932ebdfa"
          }
        },
        "b284f3ac0854497fbab925eeb1ded0df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fa221bf24cb4bdf9695b5f593b0d818",
            "placeholder": "​",
            "style": "IPY_MODEL_502de19d537d41a7b151ca5798f46a72",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "01638020753146678ee0a7692603b6c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b689e92305ae4b6693991b37e894f4a0",
            "max": 62,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_50e84fe3afd94297a3f198d0dfc4654b",
            "value": 62
          }
        },
        "6cd3e39a24fa4ed490ea0567c51c6eee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcc379d6713f47529ea18e30482cfa29",
            "placeholder": "​",
            "style": "IPY_MODEL_6d6719e9bdcc411c95f60201ee37119a",
            "value": " 62.0/62.0 [00:00&lt;00:00, 1.38kB/s]"
          }
        },
        "e0c994de1d654e92ac91d661932ebdfa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fa221bf24cb4bdf9695b5f593b0d818": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "502de19d537d41a7b151ca5798f46a72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b689e92305ae4b6693991b37e894f4a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50e84fe3afd94297a3f198d0dfc4654b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dcc379d6713f47529ea18e30482cfa29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d6719e9bdcc411c95f60201ee37119a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec2a4d26292d4606bdcee5c2a0ea5f70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cf7c0c5e780145cf90de13cd375c1cce",
              "IPY_MODEL_6cc566ec625c4251908f083a4ac5e972",
              "IPY_MODEL_ea2e9aa05204487fa884178986a59380"
            ],
            "layout": "IPY_MODEL_6ff00156a8d1407e8a03899aede36f60"
          }
        },
        "cf7c0c5e780145cf90de13cd375c1cce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57196d402589425baba759c1f92b3fee",
            "placeholder": "​",
            "style": "IPY_MODEL_931340e0216b4cdd940a7041f14b62f1",
            "value": "vocab.json: 100%"
          }
        },
        "6cc566ec625c4251908f083a4ac5e972": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccba3a5e8f3f4f08b79e5cad740b78b8",
            "max": 164540,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f762dd67830c45a1b8725313b92346e4",
            "value": 164540
          }
        },
        "ea2e9aa05204487fa884178986a59380": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc455b59103e4404b9f9b124d6999b3c",
            "placeholder": "​",
            "style": "IPY_MODEL_d178a1d70c32435482c10d6824bf4131",
            "value": " 165k/165k [00:00&lt;00:00, 1.64MB/s]"
          }
        },
        "6ff00156a8d1407e8a03899aede36f60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57196d402589425baba759c1f92b3fee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "931340e0216b4cdd940a7041f14b62f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ccba3a5e8f3f4f08b79e5cad740b78b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f762dd67830c45a1b8725313b92346e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bc455b59103e4404b9f9b124d6999b3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d178a1d70c32435482c10d6824bf4131": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7de2b548546d4c58b4e1af83cdf618e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b5c94d24b105493796b8f70d4adb55a7",
              "IPY_MODEL_be8b9e625b624ad89abb785ffdb352b9",
              "IPY_MODEL_7f60ccd803d8490f990a58518b1aa4dd"
            ],
            "layout": "IPY_MODEL_038ff99e2ffc4f7db7ecd54333a3d71e"
          }
        },
        "b5c94d24b105493796b8f70d4adb55a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_177f0b132f2f40b9b63a048635f0dc70",
            "placeholder": "​",
            "style": "IPY_MODEL_47da5e41d88d4bc6bfb496adacddba30",
            "value": "merges.txt: 100%"
          }
        },
        "be8b9e625b624ad89abb785ffdb352b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_604c8bed2d6f4c04bb9ae2b78c6f4aea",
            "max": 101307,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c83d02b54fe94d6889aae124641f43eb",
            "value": 101307
          }
        },
        "7f60ccd803d8490f990a58518b1aa4dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4df1d8407ea74a3193426b27a15eeaa9",
            "placeholder": "​",
            "style": "IPY_MODEL_67e3bc2be1034a73be1fc0b3b97da027",
            "value": " 101k/101k [00:00&lt;00:00, 1.25MB/s]"
          }
        },
        "038ff99e2ffc4f7db7ecd54333a3d71e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "177f0b132f2f40b9b63a048635f0dc70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47da5e41d88d4bc6bfb496adacddba30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "604c8bed2d6f4c04bb9ae2b78c6f4aea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c83d02b54fe94d6889aae124641f43eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4df1d8407ea74a3193426b27a15eeaa9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67e3bc2be1034a73be1fc0b3b97da027": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f53b7a64750849d18bb4df54237a1110": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f7b208a676664b59a90d7d38293df4dd",
              "IPY_MODEL_504f51d204af44b7915060072ea359b2",
              "IPY_MODEL_1f2793e435b04dc7b9502f643a98d533"
            ],
            "layout": "IPY_MODEL_c9e22b771e9e49ad8354902723d9b951"
          }
        },
        "f7b208a676664b59a90d7d38293df4dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_201c3ab1ff3a46128961e12e4edb2a01",
            "placeholder": "​",
            "style": "IPY_MODEL_bd46618a5bce46ec840bae0adb001564",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "504f51d204af44b7915060072ea359b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac00b65c79fc4b73a3e2d9d437001e3f",
            "max": 772,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d9c52550dcb8430a891ada649a35d5de",
            "value": 772
          }
        },
        "1f2793e435b04dc7b9502f643a98d533": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a99e037f63b4dbfa9d2f58912c46167",
            "placeholder": "​",
            "style": "IPY_MODEL_f89668c6b88c4bad853403c95eed4fff",
            "value": " 772/772 [00:00&lt;00:00, 13.9kB/s]"
          }
        },
        "c9e22b771e9e49ad8354902723d9b951": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "201c3ab1ff3a46128961e12e4edb2a01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd46618a5bce46ec840bae0adb001564": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac00b65c79fc4b73a3e2d9d437001e3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9c52550dcb8430a891ada649a35d5de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4a99e037f63b4dbfa9d2f58912c46167": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f89668c6b88c4bad853403c95eed4fff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gx11hYWe4hjx",
        "outputId": "7f0c1279-d448-4898-f652-0e9da18ba524",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Collecting simpletransformers\n",
            "  Downloading simpletransformers-0.70.1-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.47.0 in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (4.66.5)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (2024.9.11)\n",
            "Requirement already satisfied: transformers>=4.31.0 in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (4.44.2)\n",
            "Collecting datasets (from simpletransformers)\n",
            "  Downloading datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (1.5.2)\n",
            "Collecting seqeval (from simpletransformers)\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (2.17.0)\n",
            "Collecting tensorboardx (from simpletransformers)\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (2.2.2)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (0.19.1)\n",
            "Collecting wandb>=0.10.32 (from simpletransformers)\n",
            "  Downloading wandb-0.18.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
            "Collecting streamlit (from simpletransformers)\n",
            "  Downloading streamlit-1.39.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (0.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->simpletransformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->simpletransformers) (0.24.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->simpletransformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->simpletransformers) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->simpletransformers) (0.4.5)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.10.32->simpletransformers) (8.1.7)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb>=0.10.32->simpletransformers)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb>=0.10.32->simpletransformers)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb>=0.10.32->simpletransformers) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.10.32->simpletransformers) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.10.32->simpletransformers) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb>=0.10.32->simpletransformers)\n",
            "  Downloading sentry_sdk-2.16.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting setproctitle (from wandb>=0.10.32->simpletransformers)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb>=0.10.32->simpletransformers) (71.0.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->simpletransformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->simpletransformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->simpletransformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->simpletransformers) (2024.8.30)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->simpletransformers) (16.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->simpletransformers)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting xxhash (from datasets->simpletransformers)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets->simpletransformers)\n",
            "  Downloading multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets->simpletransformers) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->simpletransformers) (3.10.8)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->simpletransformers) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->simpletransformers) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->simpletransformers) (2024.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->simpletransformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->simpletransformers) (3.5.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->simpletransformers) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit->simpletransformers) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->simpletransformers) (5.5.0)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->simpletransformers) (10.4.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->simpletransformers) (13.9.1)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->simpletransformers) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit->simpletransformers) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->simpletransformers) (4.12.2)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit->simpletransformers)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit->simpletransformers) (6.3.3)\n",
            "Collecting watchdog<6,>=2.1.5 (from streamlit->simpletransformers)\n",
            "  Downloading watchdog-5.0.3-py3-none-manylinux2014_x86_64.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->simpletransformers) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->simpletransformers) (1.64.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->simpletransformers) (3.7)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->simpletransformers) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->simpletransformers) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->simpletransformers) (3.0.4)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit->simpletransformers) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit->simpletransformers) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit->simpletransformers) (4.23.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit->simpletransformers) (0.12.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->simpletransformers) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->simpletransformers) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->simpletransformers) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->simpletransformers) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->simpletransformers) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->simpletransformers) (1.13.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->simpletransformers) (4.0.3)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb>=0.10.32->simpletransformers)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit->simpletransformers) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit->simpletransformers) (2.18.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->simpletransformers) (2.1.5)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess (from datasets->simpletransformers)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.10.32->simpletransformers)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers) (0.20.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit->simpletransformers) (0.1.2)\n",
            "Downloading simpletransformers-0.70.1-py3-none-any.whl (316 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.3/316.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wandb-0.18.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.0.1-py3-none-any.whl (471 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading streamlit-1.39.0-py2.py3-none-any.whl (8.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentry_sdk-2.16.0-py2.py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.8/313.8 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-5.0.3-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=b97bd50c8ec6bed99549ad15982d5adc5af900fb9283cc71a8f4f3e8a5e4b8cd\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "Successfully built seqeval\n",
            "Installing collected packages: xxhash, watchdog, tensorboardx, smmap, setproctitle, sentry-sdk, docker-pycreds, dill, pydeck, multiprocess, gitdb, seqeval, gitpython, wandb, streamlit, datasets, simpletransformers\n",
            "Successfully installed datasets-3.0.1 dill-0.3.8 docker-pycreds-0.4.0 gitdb-4.0.11 gitpython-3.1.43 multiprocess-0.70.16 pydeck-0.9.1 sentry-sdk-2.16.0 seqeval-1.2.2 setproctitle-1.3.3 simpletransformers-0.70.1 smmap-5.0.1 streamlit-1.39.0 tensorboardx-2.6.2.2 wandb-0.18.3 watchdog-5.0.3 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install simpletransformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Messing around with ChemBERTa for fun and for education\n",
        "\n",
        "The first half of this colab is just fun experiments trying to understand ChemBERTa and it's tokenizer better."
      ],
      "metadata": {
        "id": "tYhe3fk-sblS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForMaskedLM, AutoTokenizer, pipeline, RobertaModel, RobertaTokenizer\n",
        "\n",
        "\n",
        "model = AutoModelForMaskedLM.from_pretrained(\"seyonec/PubChem10M_SMILES_BPE_450k\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"seyonec/PubChem10M_SMILES_BPE_450k\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420,
          "referenced_widgets": [
            "09447f7d805a456a8d9df123079fef9b",
            "491c2c5348da4cebb59112f76ff21867",
            "fe9ba8c3b518443ba11fd1e700dd2c24",
            "017803aafcb84942bd04ae4b6014d713",
            "7bb64ec2bc31458fac09dafbafc66030",
            "48ba3adb18ee45b085dcfcc74b8e4d19",
            "90c266cbe71d46aaade3ab541889fe07",
            "ed10bed1b375495cb383786278b88953",
            "0186504a6df04889965a532aeaa3058c",
            "9365963655bf4a6f9f65418af1213afb",
            "e8e0cfd2025e41cfb5ea102586988b28",
            "6b54217022de4316a071ee63832b77fe",
            "3cf79467e3384aeba7e957596b912e29",
            "d23dd09659b9428f8cc8083f44e04709",
            "a75c8346a8f74f43941aa43700e6b2d8",
            "e5968c80140b4a71978dbb453ee75af2",
            "285f3c7db7d448a7a9ed62b2f9324e53",
            "e02702dc96744f0bb3304606cfa29e24",
            "5810f7fa342f4543834d8274abe552f5",
            "433bfc6fb35a4199b1cedfbaf5f5a15e",
            "8d37ac015a0f4caebf5455c7c16284dc",
            "f3084e63613741098216632a5f92ef98",
            "1b99d732290a4190982895ff640ea719",
            "b284f3ac0854497fbab925eeb1ded0df",
            "01638020753146678ee0a7692603b6c2",
            "6cd3e39a24fa4ed490ea0567c51c6eee",
            "e0c994de1d654e92ac91d661932ebdfa",
            "2fa221bf24cb4bdf9695b5f593b0d818",
            "502de19d537d41a7b151ca5798f46a72",
            "b689e92305ae4b6693991b37e894f4a0",
            "50e84fe3afd94297a3f198d0dfc4654b",
            "dcc379d6713f47529ea18e30482cfa29",
            "6d6719e9bdcc411c95f60201ee37119a",
            "ec2a4d26292d4606bdcee5c2a0ea5f70",
            "cf7c0c5e780145cf90de13cd375c1cce",
            "6cc566ec625c4251908f083a4ac5e972",
            "ea2e9aa05204487fa884178986a59380",
            "6ff00156a8d1407e8a03899aede36f60",
            "57196d402589425baba759c1f92b3fee",
            "931340e0216b4cdd940a7041f14b62f1",
            "ccba3a5e8f3f4f08b79e5cad740b78b8",
            "f762dd67830c45a1b8725313b92346e4",
            "bc455b59103e4404b9f9b124d6999b3c",
            "d178a1d70c32435482c10d6824bf4131",
            "7de2b548546d4c58b4e1af83cdf618e7",
            "b5c94d24b105493796b8f70d4adb55a7",
            "be8b9e625b624ad89abb785ffdb352b9",
            "7f60ccd803d8490f990a58518b1aa4dd",
            "038ff99e2ffc4f7db7ecd54333a3d71e",
            "177f0b132f2f40b9b63a048635f0dc70",
            "47da5e41d88d4bc6bfb496adacddba30",
            "604c8bed2d6f4c04bb9ae2b78c6f4aea",
            "c83d02b54fe94d6889aae124641f43eb",
            "4df1d8407ea74a3193426b27a15eeaa9",
            "67e3bc2be1034a73be1fc0b3b97da027",
            "f53b7a64750849d18bb4df54237a1110",
            "f7b208a676664b59a90d7d38293df4dd",
            "504f51d204af44b7915060072ea359b2",
            "1f2793e435b04dc7b9502f643a98d533",
            "c9e22b771e9e49ad8354902723d9b951",
            "201c3ab1ff3a46128961e12e4edb2a01",
            "bd46618a5bce46ec840bae0adb001564",
            "ac00b65c79fc4b73a3e2d9d437001e3f",
            "d9c52550dcb8430a891ada649a35d5de",
            "4a99e037f63b4dbfa9d2f58912c46167",
            "f89668c6b88c4bad853403c95eed4fff"
          ]
        },
        "id": "KPjZH305wYrn",
        "outputId": "a36beb4d-b472-44c7-aed8-c200e1cc515c",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/515 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "09447f7d805a456a8d9df123079fef9b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/336M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6b54217022de4316a071ee63832b77fe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at seyonec/PubChem10M_SMILES_BPE_450k were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/62.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b99d732290a4190982895ff640ea719"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/165k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec2a4d26292d4606bdcee5c2a0ea5f70"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/101k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7de2b548546d4c58b4e1af83cdf618e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f53b7a64750849d18bb4df54237a1110"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's print the tokenizer and model's stats"
      ],
      "metadata": {
        "id": "c_UcbETKtrin"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqXGRKf_lgF1",
        "outputId": "b14003c5-a926-4d7a-dc5f-be709e2c38cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RobertaTokenizerFast(name_or_path='seyonec/PubChem10M_SMILES_BPE_450k', vocab_size=7924, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
            "\t0: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
            "\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
            "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
            "\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
            "\t4: AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=True, special=True),\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tk8oJJtMm-cJ",
        "outputId": "110c15bb-7f43-4b94-8b30-beba865b5d67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RobertaConfig {\n",
            "  \"_name_or_path\": \"seyonec/PubChem10M_SMILES_BPE_450k\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.44.2\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 52000\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "One bizarre thing to note here: The default tokenizer has a smaller vocab_size than the vocab_size of the model. What's going on? Not sure, but I think it's because the vocab_size of the model is based off usual language, where as the tokenizer is much smaller since it only needs to cover all possible SMILES. It's weird though, that they didn't adjust the vocab_size in the model. I guess that the weights for last 52000-7924 vocabs just don't count. Seems super wasteful."
      ],
      "metadata": {
        "id": "fwxVQOOGxcEX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Names of all the weights in ChemBERTa\n"
      ],
      "metadata": {
        "id": "dDxBKYAX1dDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(f\"{name} has shape {param.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zvzY6ZL3OIM",
        "outputId": "9678e0f4-3953-4eeb-d059-70d91d06609e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "roberta.embeddings.word_embeddings.weight has shape torch.Size([52000, 768])\n",
            "roberta.embeddings.position_embeddings.weight has shape torch.Size([512, 768])\n",
            "roberta.embeddings.token_type_embeddings.weight has shape torch.Size([1, 768])\n",
            "roberta.embeddings.LayerNorm.weight has shape torch.Size([768])\n",
            "roberta.embeddings.LayerNorm.bias has shape torch.Size([768])\n",
            "roberta.encoder.layer.0.attention.self.query.weight has shape torch.Size([768, 768])\n",
            "roberta.encoder.layer.0.attention.self.query.bias has shape torch.Size([768])\n",
            "roberta.encoder.layer.0.attention.self.key.weight has shape torch.Size([768, 768])\n",
            "roberta.encoder.layer.0.attention.self.key.bias has shape torch.Size([768])\n",
            "roberta.encoder.layer.0.attention.self.value.weight has shape torch.Size([768, 768])\n",
            "roberta.encoder.layer.0.attention.self.value.bias has shape torch.Size([768])\n",
            "roberta.encoder.layer.0.attention.output.dense.weight has shape torch.Size([768, 768])\n",
            "roberta.encoder.layer.0.attention.output.dense.bias has shape torch.Size([768])\n",
            "roberta.encoder.layer.0.attention.output.LayerNorm.weight has shape torch.Size([768])\n",
            "roberta.encoder.layer.0.attention.output.LayerNorm.bias has shape torch.Size([768])\n",
            "roberta.encoder.layer.0.intermediate.dense.weight has shape torch.Size([3072, 768])\n",
            "roberta.encoder.layer.0.intermediate.dense.bias has shape torch.Size([3072])\n",
            "roberta.encoder.layer.0.output.dense.weight has shape torch.Size([768, 3072])\n",
            "roberta.encoder.layer.0.output.dense.bias has shape torch.Size([768])\n",
            "roberta.encoder.layer.0.output.LayerNorm.weight has shape torch.Size([768])\n",
            "roberta.encoder.layer.0.output.LayerNorm.bias has shape torch.Size([768])\n",
            "roberta.encoder.layer.1.attention.self.query.weight has shape torch.Size([768, 768])\n",
            "roberta.encoder.layer.1.attention.self.query.bias has shape torch.Size([768])\n",
            "roberta.encoder.layer.1.attention.self.key.weight has shape torch.Size([768, 768])\n",
            "roberta.encoder.layer.1.attention.self.key.bias has shape torch.Size([768])\n",
            "roberta.encoder.layer.1.attention.self.value.weight has shape torch.Size([768, 768])\n",
            "roberta.encoder.layer.1.attention.self.value.bias has shape torch.Size([768])\n",
            "roberta.encoder.layer.1.attention.output.dense.weight has shape torch.Size([768, 768])\n",
            "roberta.encoder.layer.1.attention.output.dense.bias has shape torch.Size([768])\n",
            "roberta.encoder.layer.1.attention.output.LayerNorm.weight has shape torch.Size([768])\n",
            "roberta.encoder.layer.1.attention.output.LayerNorm.bias has shape torch.Size([768])\n",
            "roberta.encoder.layer.1.intermediate.dense.weight has shape torch.Size([3072, 768])\n",
            "roberta.encoder.layer.1.intermediate.dense.bias has shape torch.Size([3072])\n",
            "roberta.encoder.layer.1.output.dense.weight has shape torch.Size([768, 3072])\n",
            "roberta.encoder.layer.1.output.dense.bias has shape torch.Size([768])\n",
            "roberta.encoder.layer.1.output.LayerNorm.weight has shape torch.Size([768])\n",
            "roberta.encoder.layer.1.output.LayerNorm.bias has shape torch.Size([768])\n",
            "roberta.encoder.layer.2.attention.self.query.weight has shape torch.Size([768, 768])\n",
            "roberta.encoder.layer.2.attention.self.query.bias has shape torch.Size([768])\n",
            "roberta.encoder.layer.2.attention.self.key.weight has shape torch.Size([768, 768])\n",
            "roberta.encoder.layer.2.attention.self.key.bias has shape torch.Size([768])\n",
            "roberta.encoder.layer.2.attention.self.value.weight has shape torch.Size([768, 768])\n",
            "roberta.encoder.layer.2.attention.self.value.bias has shape torch.Size([768])\n",
            "roberta.encoder.layer.2.attention.output.dense.weight has shape torch.Size([768, 768])\n",
            "roberta.encoder.layer.2.attention.output.dense.bias has shape torch.Size([768])\n",
            "roberta.encoder.layer.2.attention.output.LayerNorm.weight has shape torch.Size([768])\n",
            "roberta.encoder.layer.2.attention.output.LayerNorm.bias has shape torch.Size([768])\n",
            "roberta.encoder.layer.2.intermediate.dense.weight has shape torch.Size([3072, 768])\n",
            "roberta.encoder.layer.2.intermediate.dense.bias has shape torch.Size([3072])\n",
            "roberta.encoder.layer.2.output.dense.weight has shape torch.Size([768, 3072])\n",
            "roberta.encoder.layer.2.output.dense.bias has shape torch.Size([768])\n",
            "roberta.encoder.layer.2.output.LayerNorm.weight has shape torch.Size([768])\n",
            "roberta.encoder.layer.2.output.LayerNorm.bias has shape torch.Size([768])\n",
            "roberta.encoder.layer.3.attention.self.query.weight has shape torch.Size([768, 768])\n",
            "roberta.encoder.layer.3.attention.self.query.bias has shape torch.Size([768])\n",
            "roberta.encoder.layer.3.attention.self.key.weight has shape torch.Size([768, 768])\n",
            "roberta.encoder.layer.3.attention.self.key.bias has shape torch.Size([768])\n",
            "roberta.encoder.layer.3.attention.self.value.weight has shape torch.Size([768, 768])\n",
            "roberta.encoder.layer.3.attention.self.value.bias has shape torch.Size([768])\n",
            "roberta.encoder.layer.3.attention.output.dense.weight has shape torch.Size([768, 768])\n",
            "roberta.encoder.layer.3.attention.output.dense.bias has shape torch.Size([768])\n",
            "roberta.encoder.layer.3.attention.output.LayerNorm.weight has shape torch.Size([768])\n",
            "roberta.encoder.layer.3.attention.output.LayerNorm.bias has shape torch.Size([768])\n",
            "roberta.encoder.layer.3.intermediate.dense.weight has shape torch.Size([3072, 768])\n",
            "roberta.encoder.layer.3.intermediate.dense.bias has shape torch.Size([3072])\n",
            "roberta.encoder.layer.3.output.dense.weight has shape torch.Size([768, 3072])\n",
            "roberta.encoder.layer.3.output.dense.bias has shape torch.Size([768])\n",
            "roberta.encoder.layer.3.output.LayerNorm.weight has shape torch.Size([768])\n",
            "roberta.encoder.layer.3.output.LayerNorm.bias has shape torch.Size([768])\n",
            "roberta.encoder.layer.4.attention.self.query.weight has shape torch.Size([768, 768])\n",
            "roberta.encoder.layer.4.attention.self.query.bias has shape torch.Size([768])\n",
            "roberta.encoder.layer.4.attention.self.key.weight has shape torch.Size([768, 768])\n",
            "roberta.encoder.layer.4.attention.self.key.bias has shape torch.Size([768])\n",
            "roberta.encoder.layer.4.attention.self.value.weight has shape torch.Size([768, 768])\n",
            "roberta.encoder.layer.4.attention.self.value.bias has shape torch.Size([768])\n",
            "roberta.encoder.layer.4.attention.output.dense.weight has shape torch.Size([768, 768])\n",
            "roberta.encoder.layer.4.attention.output.dense.bias has shape torch.Size([768])\n",
            "roberta.encoder.layer.4.attention.output.LayerNorm.weight has shape torch.Size([768])\n",
            "roberta.encoder.layer.4.attention.output.LayerNorm.bias has shape torch.Size([768])\n",
            "roberta.encoder.layer.4.intermediate.dense.weight has shape torch.Size([3072, 768])\n",
            "roberta.encoder.layer.4.intermediate.dense.bias has shape torch.Size([3072])\n",
            "roberta.encoder.layer.4.output.dense.weight has shape torch.Size([768, 3072])\n",
            "roberta.encoder.layer.4.output.dense.bias has shape torch.Size([768])\n",
            "roberta.encoder.layer.4.output.LayerNorm.weight has shape torch.Size([768])\n",
            "roberta.encoder.layer.4.output.LayerNorm.bias has shape torch.Size([768])\n",
            "roberta.encoder.layer.5.attention.self.query.weight has shape torch.Size([768, 768])\n",
            "roberta.encoder.layer.5.attention.self.query.bias has shape torch.Size([768])\n",
            "roberta.encoder.layer.5.attention.self.key.weight has shape torch.Size([768, 768])\n",
            "roberta.encoder.layer.5.attention.self.key.bias has shape torch.Size([768])\n",
            "roberta.encoder.layer.5.attention.self.value.weight has shape torch.Size([768, 768])\n",
            "roberta.encoder.layer.5.attention.self.value.bias has shape torch.Size([768])\n",
            "roberta.encoder.layer.5.attention.output.dense.weight has shape torch.Size([768, 768])\n",
            "roberta.encoder.layer.5.attention.output.dense.bias has shape torch.Size([768])\n",
            "roberta.encoder.layer.5.attention.output.LayerNorm.weight has shape torch.Size([768])\n",
            "roberta.encoder.layer.5.attention.output.LayerNorm.bias has shape torch.Size([768])\n",
            "roberta.encoder.layer.5.intermediate.dense.weight has shape torch.Size([3072, 768])\n",
            "roberta.encoder.layer.5.intermediate.dense.bias has shape torch.Size([3072])\n",
            "roberta.encoder.layer.5.output.dense.weight has shape torch.Size([768, 3072])\n",
            "roberta.encoder.layer.5.output.dense.bias has shape torch.Size([768])\n",
            "roberta.encoder.layer.5.output.LayerNorm.weight has shape torch.Size([768])\n",
            "roberta.encoder.layer.5.output.LayerNorm.bias has shape torch.Size([768])\n",
            "lm_head.bias has shape torch.Size([52000])\n",
            "lm_head.dense.weight has shape torch.Size([768, 768])\n",
            "lm_head.dense.bias has shape torch.Size([768])\n",
            "lm_head.layer_norm.weight has shape torch.Size([768])\n",
            "lm_head.layer_norm.bias has shape torch.Size([768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Default inference pipeline in ChemBERTa\n",
        "\n",
        "ChemBERTa is an LLM trained on the masked token task. Let's see how well it does it with an example. Below is an example of a masked smiles and what it \"should\" be. The fill-mask pipeline gives ChemBERTa's top 5 guesses"
      ],
      "metadata": {
        "id": "k13OI3jEs6-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fill_mask = pipeline('fill-mask', model=model, tokenizer=tokenizer)\n",
        "\n",
        "smiles_mask = \"C1=CC=CC<mask>C1\"\n",
        "smiles = \"C1=CC=CC=C1\"\n",
        "\n",
        "masked_smi = fill_mask(smiles_mask)\n",
        "\n",
        "for smi in masked_smi:\n",
        "  print(smi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oei2EU0DwZjU",
        "outputId": "f8ae35c0-40ab-41a5-8f78-773b59dd1f47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'score': 0.9755934476852417, 'token': 33, 'token_str': '=', 'sequence': 'C1=CC=CC=C1'}\n",
            "{'score': 0.020923908799886703, 'token': 7, 'token_str': '#', 'sequence': 'C1=CC=CC#C1'}\n",
            "{'score': 0.0007658947724848986, 'token': 21, 'token_str': '1', 'sequence': 'C1=CC=CC1C1'}\n",
            "{'score': 0.00041297602001577616, 'token': 22, 'token_str': '2', 'sequence': 'C1=CC=CC2C1'}\n",
            "{'score': 0.00025319133419543505, 'token': 352, 'token_str': '=[', 'sequence': 'C1=CC=CC=[C1'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pretty good! It gave a probability of 97% to the correct SMILES"
      ],
      "metadata": {
        "id": "ejI2RJeGtf2t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to interpret logits for other tokens?\n",
        "\n",
        "When a token isn't masked, what should you make of the logits/\"probability\" for it? For each token there a logit/prob for each of the possible 52000 tokens that could have been there. One way to intepret it is as if that token was actually masked, and the model is giving probabilities for all the tokens that could potentially go there. Another way to think of it is that it's about how \"natural\" this token is in this spot. If the model gives the token a high score for itself, it expected to see it there. Since we are giving the model a very natural sequence, we'd expect that it's scores for each of the tokens is highest for the actual token. Let's see.\n"
      ],
      "metadata": {
        "id": "7S28IjFiuA7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "sequence = f\"C1=CC=CC=CC1\"\n",
        "input = tokenizer.encode(sequence, return_tensors=\"pt\")\n",
        "\n",
        "for i in range(len(input[0])):\n",
        "    decode = tokenizer.decode(input[0][i])\n",
        "    encode = input[0][i]\n",
        "    print(f\"{decode} is the token {encode}\")\n",
        "\n",
        "token_logits = model(input)[0]\n",
        "print(f\"token logits shape {token_logits.shape}\")\n",
        "\n",
        "for i, token_id in enumerate(input[0]):\n",
        "\n",
        "    print(f\"token_id is {token_id}\")\n",
        "    # Get the logits for the i-th position\n",
        "    logits_for_token_position = token_logits[0, i, :]  # Shape: [52000], all logits for this position\n",
        "    probability_for_token_position = torch.softmax(logits_for_token_position, dim=0)\n",
        "\n",
        "    logit_for_correct_token = logits_for_token_position[token_id]\n",
        "    prob_for_correct_token = probability_for_token_position[token_id]\n",
        "    print(f\"The probability of the correct token is {round(prob_for_correct_token.item(),2)}\")\n",
        "\n",
        "    # Find the maximum logit value at this position\n",
        "    max_logit = logits_for_token_position.max().item()\n",
        "\n",
        "    # Check if the logit for the actual token is the highest\n",
        "    if logit_for_correct_token == max_logit:\n",
        "         print(f\"Position {i}: Correct: {token_id} has the highest logit.\")\n",
        "    else:\n",
        "        print(f\"Position {i}: Incorrect: {token_id} does NOT have the highest logit.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmBxqR13wfyl",
        "outputId": "ed47ce6b-652f-4e49-a012-0a919bb4cabb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> is the token 0\n",
            "C is the token 39\n",
            "1 is the token 21\n",
            "= is the token 33\n",
            "CC is the token 262\n",
            "= is the token 33\n",
            "CC is the token 262\n",
            "= is the token 33\n",
            "CC is the token 262\n",
            "1 is the token 21\n",
            "</s> is the token 2\n",
            "token logits shape torch.Size([1, 11, 52000])\n",
            "token_id is 0\n",
            "The probability of the correct token is 0.0\n",
            "Position 0: Incorrect: 0 does NOT have the highest logit.\n",
            "token_id is 39\n",
            "The probability of the correct token is 0.97\n",
            "Position 1: Correct: 39 has the highest logit.\n",
            "token_id is 21\n",
            "The probability of the correct token is 0.99\n",
            "Position 2: Correct: 21 has the highest logit.\n",
            "token_id is 33\n",
            "The probability of the correct token is 0.99\n",
            "Position 3: Correct: 33 has the highest logit.\n",
            "token_id is 262\n",
            "The probability of the correct token is 0.86\n",
            "Position 4: Correct: 262 has the highest logit.\n",
            "token_id is 33\n",
            "The probability of the correct token is 1.0\n",
            "Position 5: Correct: 33 has the highest logit.\n",
            "token_id is 262\n",
            "The probability of the correct token is 0.86\n",
            "Position 6: Correct: 262 has the highest logit.\n",
            "token_id is 33\n",
            "The probability of the correct token is 1.0\n",
            "Position 7: Correct: 33 has the highest logit.\n",
            "token_id is 262\n",
            "The probability of the correct token is 0.83\n",
            "Position 8: Correct: 262 has the highest logit.\n",
            "token_id is 21\n",
            "The probability of the correct token is 1.0\n",
            "Position 9: Correct: 21 has the highest logit.\n",
            "token_id is 2\n",
            "The probability of the correct token is 0.0\n",
            "Position 10: Incorrect: 2 does NOT have the highest logit.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The only two it got incorrect where the start and end, which is fair enough."
      ],
      "metadata": {
        "id": "GYVaGoYBw9Vt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing it out on masked sequences again- this time without the pipeline"
      ],
      "metadata": {
        "id": "FsAFLnGWfFWy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "sequence = f\"C1=CC=CC={tokenizer.mask_token}1\"\n",
        "input = tokenizer.encode(sequence, return_tensors=\"pt\")\n",
        "mask_token_index = torch.where(input == tokenizer.mask_token_id)[1]\n",
        "\n",
        "mask_token_probs = F.softmax(token_logits[0, mask_token_index, :][0], dim=0)\n",
        "top_5_tokens = torch.topk(mask_token_probs, 5).indices.tolist()\n",
        "\n",
        "for token in top_5_tokens:\n",
        "  smi = (sequence.replace(tokenizer.mask_token, tokenizer.decode([token])))\n",
        "  print (f\"{smi} has a probability of {round(mask_token_probs[token].item(),2)}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sifbg2_ifEhZ",
        "outputId": "17c33a52-bd46-4cf1-a5bf-0fee5f3aa7be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C1=CC=CC=CC1 has a probability of 0.83%\n",
            "C1=CC=CC=CNC1 has a probability of 0.04%\n",
            "C1=CC=CC=COC1 has a probability of 0.03%\n",
            "C1=CC=CC=CN1 has a probability of 0.01%\n",
            "C1=CC=CC=CCC1 has a probability of 0.01%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embeddings from ChemBERTa\n",
        "\n",
        "Each token in a SMILES sequence is embedded as a vector of dimension hidden_dimension. Then the model updates this embedding at every layer. In the last layer (before the big projection matrix back to vocab_size) the embedding is hopefully very rich and meaningful. The transformer model should have encoded important relationships between parts of the molecule into these vectors. That's why we'd like to be able to access these and use them in later parts of the model."
      ],
      "metadata": {
        "id": "WhSi8hQzefb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequence = f\"C1=CC=CC=CC1\"\n",
        "inputs = tokenizer(sequence, return_tensors=\"pt\")\n",
        "outputs = model(**inputs, output_hidden_states=True)\n",
        "hidden_states = outputs.hidden_states\n",
        "print(f\"The number of hidden states is {len(hidden_states)}, because there's one after each layer (except the last)\")\n",
        "print(f\"The shape of the hidden states is {hidden_states[0].shape}\")\n",
        "number_of_tokens = hidden_states[0].shape[1]\n",
        "hidden_dimension = hidden_states[0].shape[2]\n",
        "\n",
        "# Let's look at the embeddings in the 0th hidden state versus in the final\n",
        "original_token_embeddings = hidden_states[0][0]\n",
        "last_token_embeddings = hidden_states[-1][0]\n",
        "\n",
        "for i in range(number_of_tokens):\n",
        "    dot_product = torch.dot(original_token_embeddings[i], last_token_embeddings[i])\n",
        "    print(f\"The {i}th token has dot product between original and final of {round(dot_product.item(),2)}\")\n",
        "\n",
        "\n",
        "print(f\"On the other hand, this is what the dot product of two random vectors looks like\")\n",
        "dot_product_count = 0\n",
        "for i in range(1000):\n",
        "    random_vector1 = torch.randn(hidden_dimension)\n",
        "    random_vector2 = torch.randn(hidden_dimension)\n",
        "    dot_product_count += torch.abs(torch.dot(random_vector1, random_vector2)).item()\n",
        "\n",
        "print(f\"The average absolute value of the dot product of 100 random vectors is {round(dot_product_count/1000,2)}\")"
      ],
      "metadata": {
        "id": "Gk371_rbdteS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dffddfc5-8942-4159-dfc4-8b5ab2351a4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of hidden states is 7, because there's one after each layer (except the last)\n",
            "The shape of the hidden states is torch.Size([1, 11, 768])\n",
            "The 0th token has dot product between original and final of 39.41\n",
            "The 1th token has dot product between original and final of 39.53\n",
            "The 2th token has dot product between original and final of 114.06\n",
            "The 3th token has dot product between original and final of 59.25\n",
            "The 4th token has dot product between original and final of 12.53\n",
            "The 5th token has dot product between original and final of 73.68\n",
            "The 6th token has dot product between original and final of -13.18\n",
            "The 7th token has dot product between original and final of 83.18\n",
            "The 8th token has dot product between original and final of -1.96\n",
            "The 9th token has dot product between original and final of 89.14\n",
            "The 10th token has dot product between original and final of 112.06\n",
            "On the other hand, this is what the dot product of two random vectors looks like\n",
            "The average absolute value of the dot product of 100 random vectors is 22.08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data prep\n",
        "\n",
        "\n",
        "These are the columns in the data set:\n",
        "\n",
        "precursor_mz - f64\n",
        "precursor_charge - f64\n",
        "mzs - list[f64]\n",
        "intensities - list[f64]\n",
        "in_silico - bool\n",
        "smiles - str\n",
        "adduct - str\n",
        "collision_energy - str\n",
        "instrument_type - str\n",
        "compound_class - str\n",
        "entropy - f64\n",
        "scaffold_smiles - str"
      ],
      "metadata": {
        "id": "y_cMXHTFeMOy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the data (with pandas?)\n",
        "import pandas as pd\n",
        "\n",
        "## Load the dataset (for some reason this didn't work for me)\n",
        "#df = pd.read_parquet('enveda_library_subset 2.parquet')\n",
        "\n",
        "#print(df.head())\n",
        "\n",
        "\n",
        "# tokenize the SMILES. Do we need to pad? If so, what's the max length\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['smiles'], truncation=True, padding='max_length', max_length=128)\n",
        "\n",
        "# custom Dataset class for all the types of data.\n",
        "# I think we might want to make a new 'column' of data that combines mzs and intensities into \"label\"\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class SMILESDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.smiles = dataframe['smiles'].tolist()\n",
        "        self.precursor_mz = dataframe['precursor_mz'].tolist()\n",
        "        self.precursor_charge = dataframe['precursor_charge'].tolist()\n",
        "        self.collision_energy = dataframe['collision_energy'].tolist()\n",
        "        self.instrument_type = dataframe['instrument_type'].tolist()\n",
        "        self.in_silico_label = dataframe['in_silico_label'].tolist()\n",
        "        self.adduct = dataframe['adduct'].tolist()\n",
        "        self.compound_class = dataframe['compound_class'].tolist()\n",
        "        self.mzs = dataframe['mzs'].tolist()\n",
        "        self.intensities = dataframe['intensities'].tolist()\n",
        "\n",
        "        # Create labels as a 2D array of mzs and intensities put together. Or have it flat and just concat both\n",
        "        #self.labels = #TODO\n",
        "\n",
        "        # Create supplementary data as a long concatinated list of all the supplementary data\n",
        "        #self.supplementary_data = #TODO\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.smiles)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        smiles = self.smiles[idx]\n",
        "        precursor_mz = self.precursor_mz[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # Tokenize SMILES\n",
        "        inputs = self.tokenizer(smiles, truncation=True, padding='max_length', max_length=128, return_tensors='pt')\n",
        "\n",
        "        # Prepare item\n",
        "        item = {key: val.squeeze(0) for key, val in inputs.items()}  # Remove batch dimension\n",
        "        item['precursor_mz'] = torch.tensor(precursor_mz, dtype=torch.float)\n",
        "        item['labels'] = torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "        return item\n",
        "\n",
        "# test/train split\n",
        "# Use Murcko scaffold and spectral entropy splitting for this, rather than random.\n",
        "# This will ensure that similar molecules don't go into both training and test,\n",
        "# causing cross contamination and over fitting.\n",
        "\n",
        "def split_data(df):\n",
        "    # implement something not random here\n",
        "    return train_test_split(df, test_size=0.1, random_state=42)\n",
        "\n",
        "# train_df, eval_df = split_data(df)\n",
        "\n",
        "# train_dataset = SMILESDataset(train_df, tokenizer)\n",
        "# eval_dataset = SMILESDataset(eval_df, tokenizer)\n",
        "\n",
        "## batch?\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "nyTWxIYveLsl",
        "outputId": "b83c7ecc-b236-47ff-9062-4dcb1e3db1f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ArrowInvalid",
          "evalue": "Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-44f30e0ee309>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m## Load the dataset (no idea how to do it for the format we have)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'enveda_library_subset 2.parquet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[1;32m    665\u001b[0m     \u001b[0mcheck_dtype_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m     return impl.read(\n\u001b[0m\u001b[1;32m    668\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m         )\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m             pa_table = self.api.parquet.read_table(\n\u001b[0m\u001b[1;32m    275\u001b[0m                 \u001b[0mpath_or_handle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyarrow/parquet/core.py\u001b[0m in \u001b[0;36mread_table\u001b[0;34m(source, columns, use_threads, schema, use_pandas_metadata, read_dictionary, memory_map, buffer_size, partitioning, filesystem, filters, use_legacy_dataset, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit, page_checksum_verification)\u001b[0m\n\u001b[1;32m   1760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1762\u001b[0;31m         dataset = ParquetDataset(\n\u001b[0m\u001b[1;32m   1763\u001b[0m             \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m             \u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyarrow/parquet/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_paths, filesystem, schema, filters, read_dictionary, memory_map, buffer_size, partitioning, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit, page_checksum_verification, use_legacy_dataset)\u001b[0m\n\u001b[1;32m   1327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m             self._dataset = ds.FileSystemDataset(\n\u001b[0;32m-> 1329\u001b[0;31m                 \u001b[0;34m[\u001b[0m\u001b[0mfragment\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschema\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfragment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphysical_schema\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1330\u001b[0m                 \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparquet_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m                 \u001b[0mfilesystem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfragment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilesystem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyarrow/_dataset.pyx\u001b[0m in \u001b[0;36mpyarrow._dataset.Fragment.physical_schema.__get__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyarrow/error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyarrow/error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mArrowInvalid\u001b[0m: Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom model for our problem\n",
        "This is probably the most important part in terms of design choices. We are changing the ChemBERTa model by adding on something at the end. This new module will take the hidden SMILES embedding from the last hidden layer as input. It will also take in all the other data about the precusor molecule and experimental conditions (eg, precusor mz, collison energy etc). For now, let's call that supplementary data.\n",
        "\n",
        "I've written the simplest possible thing here: a single linear layer that takes the embedding of the entire seq, concatinated with all the supplementary data for the example. It outputs \"labels\", which is mzs and intensities zipped together.\n",
        "\n",
        "The reason for making a single module output both mzs and intensities is because there needs to be the same number of fragments per example, and the two numbers are very related.\n",
        "\n",
        "A single linear layer is probably a terrible choice though, since this is the only layer that sees all the supplementary data."
      ],
      "metadata": {
        "id": "fENovYIHeaOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import einops\n",
        "\n",
        "max_fragments = 10 #find out what the maximum number of fragments is in the data\n",
        "\n",
        "class CustomChemBERTaModel(nn.Module):\n",
        "    def __init__(self, model):\n",
        "        super(CustomChemBERTaModel, self).__init__()\n",
        "        self.model = model\n",
        "\n",
        "        # Get hidden size from the ChemBERTa model configuration\n",
        "        hidden_size = self.model.config.hidden_size\n",
        "        seq_length = 128 #Should we set a max sequence length and pad like this?\n",
        "\n",
        "        # Define a linear layer to output 2 numbers (mz and intensity) per fragment\n",
        "        self.linear = nn.Linear(hidden_size * seq_length, 2 * max_fragments)\n",
        "\n",
        "    def forward(self, input_ids, supplementary_data=None, labels=None):\n",
        "        # Pass inputs through ChemBERTa\n",
        "        outputs = self.model(input_ids=input_ids, output_hidden_states=True)\n",
        "\n",
        "        # Extract last hidden state (embeddings)\n",
        "        last_hidden_state = outputs.hidden_state[-1]\n",
        "        flatten_hidden_state = einops.rearrange(last_hidden_state, 'b s h -> b (s h)')\n",
        "\n",
        "        # Pass in supplementary data and then contat it with flatten_hidden_state\n",
        "        # state = contat(flatten_hidden_state, supplementary_data) #TODO\n",
        "\n",
        "        # Pass through the linear layer\n",
        "        predicted_output_flat = self.linear(state)  # Shape: [batch_size, 2 * max_fragments]\n",
        "        predicted_output = einops.rearrange(predicted_output_flat, 'b (h f) -> b h f', f=max_fragments)\n",
        "\n",
        "        # calculate the loss by comparing to labels\n",
        "        loss = 0 #TODO use the loss function they mentioned on discord (I think dot product similarity)\n",
        "\n",
        "        return predicted_output, loss\n",
        "\n",
        "#MS_model = CustomChemBERTaModel(model, supplementary_data, labels)"
      ],
      "metadata": {
        "id": "rMogXqZteZ1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LoRA config\n"
      ],
      "metadata": {
        "id": "IDwMMYCaYAZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "peft_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.1,\n",
        "    target_modules=[\"key\", \"query\", \"value\"] # they seem to drop off the \"key\" often?\n",
        "    modules_to_save=[\"classifier\"] # change this to the name of the new modules at the end.\n",
        "    bias=\"none\"\n",
        ")\n",
        "\n",
        "peft_model = get_peft_model(model, peft_config)\n",
        "\n",
        "# I don't think this is stickly necessary?\n",
        "# In fact, may even be bad since it might freeze params in our last layer:\n",
        "for param in peft_model.base_model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "model = get_peft_model(model, config)\n",
        "model.print_trainable_parameters() #check that it's training the right things"
      ],
      "metadata": {
        "id": "y0PF6-qGZ683"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the Model"
      ],
      "metadata": {
        "id": "-q-zpo0kaF0p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=data_collator)\n",
        "optimizer = AdamW(peft_model.parameters(), lr=5e-5)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "peft_model.to(device)\n",
        "peft_model.train()\n",
        "\n",
        "for epoch in range(training_args.num_train_epochs):\n",
        "    for batch in train_loader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        supplementary_data = batch['supplementary_data'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = peft_model(\n",
        "            input_ids=input_ids,\n",
        "            supplementary_data=supplementary_data,\n",
        "            labels=labels\n",
        "        )\n",
        "        loss = outputs[1]\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n"
      ],
      "metadata": {
        "id": "I3YvQNVqcGyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "01jClKYXdZ-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_inference_input(smiles, precursor_mz):\n",
        "    inputs = tokenizer(smiles, truncation=True, padding='max_length', max_length=128, return_tensors='pt')\n",
        "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
        "    inputs['supplementary_data'] = torch.tensor([supplementary_data], dtype=torch.float).to(device)\n",
        "    return inputs\n",
        "\n",
        "peft_model.eval()\n",
        "\n",
        "# Example data\n",
        "smiles_example = \"CCO\"\n",
        "supplementary_data_example = 0 #TODO\n",
        "\n",
        "# Prepare input\n",
        "inputs = prepare_inference_input(smiles_example, supplementary_data_example)\n",
        "\n",
        "# Inference\n",
        "with torch.no_grad():\n",
        "    outputs = peft_model(**inputs)\n",
        "    logits = outputs[0]\n"
      ],
      "metadata": {
        "id": "0FDkmqV7dXNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Choices that affect the whole architecture\n",
        "\n",
        "*   Format for the supplementary data\n",
        "*   Format for the label data\n",
        "*   The format of the output of the new model\n",
        "\n",
        "\n",
        "\n",
        "### More modular choices (that are important)\n",
        "\n",
        "\n",
        "*   Whether we have to predict compound_class at inference\n",
        "*   Include in_silico data?\n",
        "*   Architeture of the modified ChemBERTa model\n",
        "*   LoRA parameters\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2D8bfVV9keeM"
      }
    }
  ]
}